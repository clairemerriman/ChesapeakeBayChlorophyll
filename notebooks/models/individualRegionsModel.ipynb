{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1726749716803,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"B4cTM3ojIp06","outputId":"66365b7e-ecf3-4bd7-dbdb-f7da072a6de1"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","# %cd /content/drive/MyDrive/ChesapeakeBay/ChesapeakeBayChlorophyll/notebooks/models"]},{"cell_type":"markdown","metadata":{"id":"NfAM04byIp09"},"source":["# Set up"]},{"cell_type":"code","execution_count":140,"metadata":{"executionInfo":{"elapsed":5970,"status":"ok","timestamp":1726749724905,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"5lKH0EkzIp0-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import xarray as xr\n","import matplotlib.pyplot as plt\n","import os\n","\n","import logging\n","from tqdm.notebook import tqdm  # For progress bar\n","# Configure logging instead of print\n","logging.basicConfig(filename='tuning.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","from sklearn.model_selection import ParameterGrid\n","import json\n","from concurrent.futures import ThreadPoolExecutor, as_completed"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Region 0: features tensor shape: torch.Size([2767, 7, 127]), chlorophyll tensor shape: torch.Size([2767, 127])\n","Region 1: features tensor shape: torch.Size([2767, 7, 236]), chlorophyll tensor shape: torch.Size([2767, 236])\n","Region 2: features tensor shape: torch.Size([2767, 7, 311]), chlorophyll tensor shape: torch.Size([2767, 311])\n","Region 3: features tensor shape: torch.Size([2767, 7, 769]), chlorophyll tensor shape: torch.Size([2767, 769])\n","Region 4: features tensor shape: torch.Size([2767, 7, 1234]), chlorophyll tensor shape: torch.Size([2767, 1234])\n","Region 5: features tensor shape: torch.Size([2767, 7, 602]), chlorophyll tensor shape: torch.Size([2767, 602])\n","Region 6: features tensor shape: torch.Size([2767, 7, 1251]), chlorophyll tensor shape: torch.Size([2767, 1251])\n","Region 7: features tensor shape: torch.Size([2767, 7, 335]), chlorophyll tensor shape: torch.Size([2767, 335])\n","Region 8: features tensor shape: torch.Size([2767, 7, 195]), chlorophyll tensor shape: torch.Size([2767, 195])\n","Region 9: features tensor shape: torch.Size([2767, 7, 283]), chlorophyll tensor shape: torch.Size([2767, 283])\n","Region 10: features tensor shape: torch.Size([2767, 7, 743]), chlorophyll tensor shape: torch.Size([2767, 743])\n"]}],"source":["# Load tensors\n","# features_tensor = torch.load('../../data/features_masked_tensor.pt')\n","# chlorophyll_tensor = torch.load('../../data/chlorophyll_masked_tensor.pt')\n","\n","features_tensor_dict = {}\n","\n","for i in range(11):\n","    # Load tensors using formatted string (f-string)\n","    features_tensor = torch.load(f'../../data/filesForModel/tensors/features_region{i}_tensor.pt')\n","    chlorophyll_tensor = torch.load(f'../../data/filesForModel/tensors/chlorophyll_region{i}_tensor.pt')\n","\n","    # # Attach names to tensor dimensions\n","    # features_tensor.names = ('time','features','position')\n","    # chlorophyll_tensor.names = ('time','position')\n","\n","    # Store the tensors in the dictionary\n","    features_tensor_dict[f'region_{i}_features'] = features_tensor\n","    features_tensor_dict[f'region_{i}_chlorophyll'] = chlorophyll_tensor\n","\n","    print(f\"Region {i}: features tensor shape: {features_tensor.shape}, chlorophyll tensor shape: {chlorophyll_tensor.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"elw_9KwpIp1D"},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["We will create create a data stream for each of the 11 regions. Within each of these regions, we use a long short-term memory model (LSTM) to predict the chlorophyll values at each point.\n","\n","Since the regions are highly irregular in shape, the position grid (latitude and longitude) contains a lot of points outside of the region. These positions have NaN for every variable, so we need to mask them in our model."]},{"cell_type":"markdown","metadata":{"id":"1JjbhYbjIp1D"},"source":["## Defining the classes"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"TqW4f2jxIp1D"},"outputs":[],"source":["class RegionalLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size,h0=None, c0=None):\n","        super(RegionalLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","\n","        # Store hidden states if needed\n","        self.h0 = h0\n","        self.c0 = c0\n","    def forward(self, x, h0=None, c0=None, time_batch_size= 100):\n","        # x shape: (batch_size, time_steps, variables, position)\n","        batch_size, time_steps, variables, positions = x.size()\n","        x = x.to(device)\n","        # Reshape to (batch_size * position, time_steps, variables) to treat each position separately\n","        x = x.permute(0, 3, 1, 2).reshape(batch_size * positions, time_steps, variables)\n","\n","        # If no hidden state provided, initialize hidden states\n","        if h0 is None or c0 is None:\n","            h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","            c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","\n","\n","        # Adjust mini-batching to handle cases where time_steps < time_batch_size\n","        outputs = []\n","        for start in range(0, time_steps, time_batch_size):\n","            end = min(start + time_batch_size, time_steps)\n","            x_time_batch = x[:, start:end, :]  # Mini-batch along time\n","            \n","            # Forward pass through the LSTM with hidden state carryover\n","            lstm_out, (h0, c0) = self.lstm(x_time_batch, (h0, c0))  # Keep hidden state across time mini-batches\n","            \n","            outputs.append(lstm_out)\n","        \n","        # Concatenate the outputs for all time mini-batches\n","        lstm_out = torch.cat(outputs, dim=1)  # Concatenate along the time dimension\n","        \n","        # Apply the fully connected layer at every time step for each position\n","        out = self.fc(lstm_out)  # Shape: (batch_size * positions, time_steps, output_size)\n","        \n","        # Reshape back to (batch_size, time_steps, positions)\n","        out = out.view(batch_size, positions, time_steps).permute(0, 2, 1)\n","\n","        \n","        return out, (h0,c0)\n"]},{"cell_type":"markdown","metadata":{},"source":["Since the relationship between regions comes from a map, we will hard code the data. Simply using a 1 if the regions border each other and 0 if they do not."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Neighbor mask matrix (as described earlier)\n","neighbor_mask = torch.tensor([\n","    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Region 0, CB1TF\n","    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # Region 1, CB2OH\n","    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # Region 2, CB3MH\n","    [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],  # Region 3, CB4MH\n","    [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1],  # Region 4, CB5MH\n","    [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0],  # Region 5, CB6PH\n","    [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],  # Region 6, CB7PH\n","    [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],  # Region 7, CB8PH\n","    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # Region 8, EASMH\n","    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # Region 9, MOBPH\n","    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]   # Region 110, TANMH\n","], dtype=torch.float32)"]},{"cell_type":"markdown","metadata":{},"source":["And we will generate a class that handles all regions, sharing hidden states between neighboring regions."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class MultiRegionModel(nn.Module):\n","    def __init__(self, neighbor_mask, input_size, hidden_size, num_layers, output_size):\n","        super(MultiRegionModel, self).__init__()\n","        self.neighbor_mask = neighbor_mask\n","        self.regions = nn.ModuleList([\n","            RegionalLSTM(input_size, hidden_size, num_layers, output_size) \n","            for _ in range(neighbor_mask.shape[0])\n","        ])\n","\n","\n","    def forward(self, region_inputs):\n","        # region_inputs should be a dictionary where keys are region IDs and values are feature tensors\n","        region_outputs = {}  # Initialize a dictionary to store outputs for each region\n","\n","        for region_id, region_data in region_inputs.items():\n","            # Assuming region_id can be converted to an index\n","            region_index = int(region_id[-1])\n","            # Initialize combined_h0 for the first pass\n","            position_size = region_data.shape[-1]\n","            current_h0 = torch.zeros((batch_size, position_size, self.regions[region_index].lstm.hidden_size)).to(device)  # Replace with appropriate shape\n","\n","            # Find neighbors\n","            neighbors = [i for i in range(1, self.neighbor_mask.shape[0] ) if self.neighbor_mask[region_index, i] == 1]\n","\n","            neighbor_hidden_states = []\n","            for neighbor_index in neighbors:\n","                _, (neighbor_h0, neighbor_c0) = self.regions[neighbor_index](region_data)  # Use region_data for the neighbor\n","\n","                neighbor_hidden_states.append(neighbor_h0)\n","                # Assuming neighbor_hidden_states is a list of (batch_size * positions, time_steps, hidden_size) tensors\n","            if neighbor_hidden_states:\n","                aggregated_neighbors_h0 = torch.mean(torch.stack(neighbor_hidden_states), dim=0).to(device)  # Mean across neighbors\n","\n","            # Combine current hidden state with aggregated neighbor hidden states\n","            combined_h0 = current_h0 + F.interpolate(aggregated_neighbors_h0, size=current_h0.shape[-1], mode='linear', align_corners=False).to(device)\n","            # Adjust this operation as needed\n","\n","            # Call the RegionalLSTM with the current input and updated hidden states\n","            output, (current_h0, current_c0) = self.regions[region_index](region_data, combined_h0, neighbor_c0)\n","\n","            # Store the output for the current region\n","            region_outputs[region_id] = output.to(device)# Store the output for the current region\n","        return region_outputs  # Return the dictionary of outputs for each region\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Region 0: Train features torch.Size([1, 1936, 7, 127]), Validation features torch.Size([1, 415, 7, 127]), Test features torch.Size([1, 416, 7, 127])\n","Region 0: Train targets torch.Size([1, 1936, 127]), Validation targets torch.Size([1, 415, 127]), Test targets torch.Size([1, 416, 127])\n","Region 1: Train features torch.Size([1, 1936, 7, 236]), Validation features torch.Size([1, 415, 7, 236]), Test features torch.Size([1, 416, 7, 236])\n","Region 1: Train targets torch.Size([1, 1936, 236]), Validation targets torch.Size([1, 415, 236]), Test targets torch.Size([1, 416, 236])\n","Region 2: Train features torch.Size([1, 1936, 7, 311]), Validation features torch.Size([1, 415, 7, 311]), Test features torch.Size([1, 416, 7, 311])\n","Region 2: Train targets torch.Size([1, 1936, 311]), Validation targets torch.Size([1, 415, 311]), Test targets torch.Size([1, 416, 311])\n","Region 3: Train features torch.Size([1, 1936, 7, 769]), Validation features torch.Size([1, 415, 7, 769]), Test features torch.Size([1, 416, 7, 769])\n","Region 3: Train targets torch.Size([1, 1936, 769]), Validation targets torch.Size([1, 415, 769]), Test targets torch.Size([1, 416, 769])\n","Region 4: Train features torch.Size([1, 1936, 7, 1234]), Validation features torch.Size([1, 415, 7, 1234]), Test features torch.Size([1, 416, 7, 1234])\n","Region 4: Train targets torch.Size([1, 1936, 1234]), Validation targets torch.Size([1, 415, 1234]), Test targets torch.Size([1, 416, 1234])\n","Region 5: Train features torch.Size([1, 1936, 7, 602]), Validation features torch.Size([1, 415, 7, 602]), Test features torch.Size([1, 416, 7, 602])\n","Region 5: Train targets torch.Size([1, 1936, 602]), Validation targets torch.Size([1, 415, 602]), Test targets torch.Size([1, 416, 602])\n","Region 6: Train features torch.Size([1, 1936, 7, 1251]), Validation features torch.Size([1, 415, 7, 1251]), Test features torch.Size([1, 416, 7, 1251])\n","Region 6: Train targets torch.Size([1, 1936, 1251]), Validation targets torch.Size([1, 415, 1251]), Test targets torch.Size([1, 416, 1251])\n","Region 7: Train features torch.Size([1, 1936, 7, 335]), Validation features torch.Size([1, 415, 7, 335]), Test features torch.Size([1, 416, 7, 335])\n","Region 7: Train targets torch.Size([1, 1936, 335]), Validation targets torch.Size([1, 415, 335]), Test targets torch.Size([1, 416, 335])\n","Region 8: Train features torch.Size([1, 1936, 7, 195]), Validation features torch.Size([1, 415, 7, 195]), Test features torch.Size([1, 416, 7, 195])\n","Region 8: Train targets torch.Size([1, 1936, 195]), Validation targets torch.Size([1, 415, 195]), Test targets torch.Size([1, 416, 195])\n","Region 9: Train features torch.Size([1, 1936, 7, 283]), Validation features torch.Size([1, 415, 7, 283]), Test features torch.Size([1, 416, 7, 283])\n","Region 9: Train targets torch.Size([1, 1936, 283]), Validation targets torch.Size([1, 415, 283]), Test targets torch.Size([1, 416, 283])\n","Region 10: Train features torch.Size([1, 1936, 7, 743]), Validation features torch.Size([1, 415, 7, 743]), Test features torch.Size([1, 416, 7, 743])\n","Region 10: Train targets torch.Size([1, 1936, 743]), Validation targets torch.Size([1, 415, 743]), Test targets torch.Size([1, 416, 743])\n"]}],"source":["train_features_dict = {}\n","val_features_dict = {}\n","test_features_dict = {}\n","train_targets_dict = {}\n","val_targets_dict = {}\n","test_targets_dict = {}\n","\n","# feature shape (time, variables, position)\n","# chlorophyll shape (time, position)\n","for region_id in range(11):\n","    # Access the features and chlorophyll tensors from the dictionary\n","    features_tensor = features_tensor_dict[f'region_{region_id}_features']\n","    chlorophyll_tensor = features_tensor_dict[f'region_{region_id}_chlorophyll']\n","\n","    # reshape to (batch, time, variables, position)\n","    features_tensor = features_tensor.unsqueeze(0)\n","    chlorophyll_tensor = chlorophyll_tensor.unsqueeze(0)\n","    \n","    # Split data into 70% training, 15% validation, 15% test\n","    train_size = int(0.7 * features_tensor.shape[1])  # 70% of the time steps\n","    val_size = int(0.15 * features_tensor.shape[1])   # 15% for validation\n","    test_size = features_tensor.shape[1] - train_size - val_size  # Remaining for test set\n","\n","    # Split features into train, validation, and test sets\n","    train_features = features_tensor[:, :train_size, :, :]  # First 70% for training\n","    val_features = features_tensor[:, train_size:train_size+val_size, :, :]  # Next 15% for validation\n","    test_features = features_tensor[:, train_size+val_size:, :, :]  # Remaining for test\n","    \n","    # Split chlorophyll targets (same logic)\n","    train_targets = chlorophyll_tensor[:, :train_size, :]  # First 70% for training\n","    val_targets = chlorophyll_tensor[:, train_size:train_size+val_size, :]  # Next 15% for validation\n","    test_targets = chlorophyll_tensor[:, train_size+val_size:, :]  # Remaining for test\n","\n","    # Store the splits in dictionaries\n","    # Also correct the indexing\n","    train_features_dict[f'region_{region_id}'] = train_features\n","    val_features_dict[f'region_{region_id}'] = val_features\n","    test_features_dict[f'region_{region_id}'] = test_features\n","    \n","    train_targets_dict[f'region_{region_id}'] = train_targets\n","    val_targets_dict[f'region_{region_id}'] = val_targets\n","    test_targets_dict[f'region_{region_id}'] = test_targets\n","\n","    # Print shapes for verification\n","    print(f\"Region {region_id}: Train features {train_features.shape}, Validation features {val_features.shape}, Test features {test_features.shape}\")\n","    print(f\"Region {region_id}: Train targets {train_targets.shape}, Validation targets {val_targets.shape}, Test targets {test_targets.shape}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Tuning each region separately\n","\n","We will compare the results to training each region separately, without any shared hidden states."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_and_evaluate_region(model, region_id, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, learning_rate, num_epochs):\n","    # Define loss function and optimizer\n","    criterion = nn.MSELoss()  # Mean Squared Error for regression\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    best_validation_loss = float('inf')\n","    no_improvement_count = 0  # Counter for epochs without improvement\n","\n","    # Move model to GPU if available\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    validation_losses = []\n","\n","    for epoch in tqdm(range(num_epochs),desc=f\"Processing {region_id}\",leave=False):\n","        features = train_features_dict[region_id]\n","        targets = train_targets_dict[region_id]\n","\n","        features = features.to(device)\n","        targets = targets.to(device)\n","\n","        model.train()  # Ensure the model is in training mode before each training step\n","\n","        # Retrieve output for the specific region\n","        output, _ = model(features)\n","\n","        # Compute loss\n","        loss = criterion(output, targets)\n","\n","        # Backpropagation and optimization steps\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation step \n","        model.eval()  # Set model to evaluation mode\n","        val_features = val_features_dict[region_id].to(device)\n","        val_targets = val_targets_dict[region_id].to(device)\n","\n","        with torch.no_grad():  # Disable gradient calculation for validation\n","            val_output,_ = model(val_features)\n","            val_loss = criterion(val_output, val_targets)\n","            validation_losses.append(val_loss.item())  # Store the loss in the dictionary\n","\n","        # Early stopping logic\n","        if val_loss < best_validation_loss:\n","            best_validation_loss = val_loss\n","            no_improvement_count = 0  # Reset counter\n","            # Save the best model state\n","        else:\n","            no_improvement_count += 1\n","            if no_improvement_count >= 10:\n","                print(f\"Stopping early at epoch {epoch + 1} due to no improvement.\")\n","                break  # Stop training\n","\n","        del val_features, val_targets  # Clear these variables\n","\n","    return validation_losses  # Return losses for each region separately\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = RegionalLSTM(input_size=7,hidden_size=2, num_layers=2,output_size=1)\n","\n","validation_losses_dict = {}\n","\n","for region_id in train_features_dict.keys():\n","    validation_losses = train_and_evaluate_region(model, region_id, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, learning_rate=0.01, num_epochs=10)\n","    validation_losses_dict[region_id] = validation_losses\n","\n","validation_losses_dict"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def hyperparameter_tuning_region(params,region_id, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict):\n","    checked_params_file = f'checkpoints/checked_{region_id}_params.json'  # Define the path for the checked parameters file\n","    checkpoint_path = f'checkpoints/model_{region_id}_checkpoint.pt'  # Define the path for the checked parameters file\n","\n","\n","    if os.path.exists(checked_params_file):\n","        with open(checked_params_file, 'r') as f:\n","            checked_params = json.load(f)  # Load as a dictionary\n","    else:\n","        checked_params = {}  # Initialize an empty dictionary if no file exists\n","    \n","    if os.path.exists(checkpoint_path):\n","        checkpoint = torch.load(checkpoint_path)\n","        best_model = checkpoint['model']  # Load the best model\n","        best_params = checkpoint['params']  # Load the best parameters\n","        best_validation_loss = checkpoint['validation_loss']  # Load the best individual validation losses\n","    else:\n","        best_model = None\n","        best_params = None\n","        best_validation_loss = float('inf')\n","\n","    no_improvement_count = 0  # Counter for epochs without improvement\n","\n","\n","    # Iterate through each combination of hyperparameters\n","\n","    with tqdm(total=len(ParameterGrid(params)), desc=\"Processing Model\", leave=True) as pbar:\n","\n","        for param_combination in ParameterGrid(params):\n","            tqdm.write(f\"Training region {region_id} with parameters: {param_combination}\")\n","            \n","            # Skip already checked parameters\n","            params_key = json.dumps(param_combination, sort_keys=True)\n","            if params_key in checked_params:\n","                pbar.update(1)\n","                continue\n","            \n","            model = RegionalLSTM(input_size=input_size,\n","                                hidden_size=param_combination['hidden_size'],\n","                                num_layers=param_combination['num_layers'],\n","                                output_size=1)  # output_size is fixed\n","            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","            model.to(device)\n","            \n","            # Initialize the model with the current parameters\n","            validation_losses = train_and_evaluate_region(\n","                model.to(device),\n","                region_id,\n","                train_features_dict, \n","                train_targets_dict, \n","                val_features_dict, \n","                val_targets_dict,\n","                param_combination['learning_rate'],\n","                param_combination['num_epochs']\n","                )\n","            \n","            checked_params[params_key] = validation_losses  # Store the validation loss for this combination\n","\n","            # Save the updated checked parameters dictionary to the file\n","            with open(checked_params_file, 'w') as f:\n","                json.dump(checked_params, f)\n","\n","            # Finds the validation loss for these parameters\n","            most_recent_losses = validation_losses[-1]\n","\n","\n","            # Update best model if the current one is better\n","            if most_recent_losses < best_validation_loss:\n","                best_validation_loss = most_recent_losses\n","                best_model = model\n","                best_params = param_combination\n","                no_improvement_count = 0  # Reset counter for improvements\n","\n","\n","                # Save the best model to a checkpoint\n","                torch.save({\n","                    'model': best_model.state_dict(),  # Save the model state\n","                    'params': best_params,  # Save the best parameters\n","                    'validation_loss': best_validation_loss,  # Save the best individual validation losses\n","                }, checkpoint_path)\n","            else:\n","                no_improvement_count += 1  # Increment if there's no improvement\n","                if no_improvement_count >= 10:\n","                    pbar.update(1)\n","                    tqdm.write(f\"Stopping early for region {region_id} due to no improvement in hyperparameters.\")\n","                    break  # Stop tuning if no improvement for `patience` configurations\n","\n","\n","        # Clear the model from memory after saving\n","            del model\n","\n","    print(f\"Best parameters: {best_params} with average validation loss: {best_validation_loss}\")\n","    return best_model, best_params, best_validation_loss\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size=1\n","input_size= 7\n","param_grid = {\n","    'hidden_size': [8, 16, 32],  \n","    'num_layers': [2,3,4],      \n","    'learning_rate': [0.005, 0.01, 0.05],  \n","    'num_epochs': [10,50,100]         \n","}\n","best_model_dict ={}\n","\n","for region_id in tqdm(train_features_dict.keys()):\n","    best_model, best_params, best_validation_loss = hyperparameter_tuning_region(param_grid,region_id, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict)\n","    best_model_dict[region_id] = {\"model\": best_model,\n","                                  \"parameters\" : best_params,\n","                                  \"validation loss\" : best_validation_loss}"]},{"cell_type":"code","execution_count":166,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["region_0 {'hidden_size': 8, 'learning_rate': 0.05, 'num_epochs': 100, 'num_layers': 3} 0.0017464755801483989\n","region_1 {'hidden_size': 16, 'learning_rate': 0.01, 'num_epochs': 100, 'num_layers': 2} 0.009564106352627277\n","region_2 {'hidden_size': 8, 'learning_rate': 0.05, 'num_epochs': 10, 'num_layers': 2} 0.011376007460057735\n","region_3 {'hidden_size': 8, 'learning_rate': 0.05, 'num_epochs': 100, 'num_layers': 2} 0.03326268866658211\n","region_4 {'hidden_size': 16, 'learning_rate': 0.005, 'num_epochs': 100, 'num_layers': 2} 0.00023831402359064668\n","region_5 {'hidden_size': 8, 'learning_rate': 0.005, 'num_epochs': 100, 'num_layers': 2} 0.0003620159695856273\n","region_6 {'hidden_size': 8, 'learning_rate': 0.01, 'num_epochs': 100, 'num_layers': 2} 0.00033450324553996325\n","region_7 {'hidden_size': 8, 'learning_rate': 0.005, 'num_epochs': 10, 'num_layers': 2} 0.0009532846161164343\n","region_8 {'hidden_size': 8, 'learning_rate': 0.05, 'num_epochs': 100, 'num_layers': 2} 0.0030453114304691553\n","region_9 {'hidden_size': 8, 'learning_rate': 0.01, 'num_epochs': 100, 'num_layers': 2} 0.004979727789759636\n","region_10 {'hidden_size': 8, 'learning_rate': 0.01, 'num_epochs': 10, 'num_layers': 2} 0.002518851077184081\n"]}],"source":["for region_id in train_features_dict.keys():\n","        if os.path.exists(f'checkpoints/model_{region_id}_checkpoint.pt'):\n","                checkpoint = torch.load(f'checkpoints/model_{region_id}_checkpoint.pt')\n","                best_model = checkpoint['model']  # Load the best model\n","                best_params = checkpoint['params']  # Load the best parameters\n","                best_validation_loss = checkpoint['validation_loss']  # Load the best individual validation losses\n","                print(region_id,best_params, best_validation_loss)\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we will compare test these models on the testing sets."]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[],"source":["def test_regional_model(region_id, test_features_dict,test_targets_dict):\n","    test_dataset = test_features_dict[region_id]\n","    test_targets = test_targets_dict[region_id]\n","    \n","    checkpoint_path = f'checkpoints/model_{region_id}_checkpoint.pt'  # Define the path for the checked parameters file\n","\n","    checkpoint = torch.load(checkpoint_path)\n","    best_params = checkpoint['params']\n","\n","    input_size = test_dataset.shape[2]\n","    hidden_size = best_params['hidden_size']\n","    num_layers = best_params['num_layers']\n","\n","    model = RegionalLSTM(input_size, hidden_size, num_layers,output_size=1)\n","    model.load_state_dict(checkpoint['model'])  # Load the best model\n","    model.eval() \n","\n","    criterion = nn.MSELoss()\n","    with torch.no_grad():  # Disable gradient calculation\n","        output,_ = model(test_dataset)  \n","\n","    true_values = test_targets  # Ensure true_values is in the correct shape\n","    error = criterion(output, true_values)\n","\n","    return output, error  # Return predictions and metrics if needed"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["region_0 tensor(0.0017)\n","region_1 tensor(0.0096)\n","region_2 tensor(0.0114)\n","region_3 tensor(0.0333)\n","region_4 tensor(0.0002)\n","region_5 tensor(0.0004)\n","region_6 tensor(0.0003)\n","region_7 tensor(0.0010)\n","region_8 tensor(0.0030)\n","region_9 tensor(0.0050)\n","region_10 tensor(0.0025)\n"]}],"source":["region_outputs_dict ={}\n","for region_id, dictionary in best_model_dict.items():\n","    output, error = test_regional_model(region_id, test_features_dict,test_targets_dict)\n","    region_outputs_dict[region_id] = {\"prediction\" : output, \"mean squared error\": error}\n","    print(region_id,error)"]},{"cell_type":"markdown","metadata":{},"source":["## Hypertuning full model"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["def train_and_evaluate_model(model, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, learning_rate,num_epochs):\n","\n","    # Define loss function and optimizer\n","    criterion = nn.MSELoss()  # Mean Squared Error for regression\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","    # Move model to GPU if available\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    last_outputs_dict = {region_id: [] for region_id in train_features_dict.keys()}\n","    validation_losses = {region_id: [] for region_id in val_features_dict.keys()}\n","    region_models ={}\n","\n","    total_iterations = num_epochs * len(train_features_dict)\n","\n","    with tqdm(total=total_iterations, desc=\"Processing Model\", leave=True) as pbar:\n","        for epoch in range(num_epochs):\n","          for region_id, features in train_features_dict.items():\n","\n","                targets = train_targets_dict[region_id]\n","\n","                features = features.to(device)\n","                targets = targets.to(device)\n","                \n","                model.train() # Ensure the model is in training mode before each training step\n","\n","                # Forward pass: get the outputs for all regions\n","                region_outputs = model({region_id: features})\n","                \n","                region_models[region_id]=model\n","                # Retrieve output for the specific region\n","                output = region_outputs[region_id]\n","                \n","                # Store for SHAP \n","                last_outputs_dict[region_id].append(output.detach().cpu().numpy())  # Detach and move to CPU if necessary\n","\n","                # Compute loss\n","                loss = criterion(output, targets)\n","\n","                # Backpropagation and optimization steps\n","                optimizer.zero_grad()\n","                loss.backward()\n","                optimizer.step()\n","\n","                # Validation step \n","                model.eval()  # Set model to evaluation mode\n","                val_features = val_features_dict[region_id].to(device)\n","                val_targets = val_targets_dict[region_id].to(device)\n","\n","                with torch.no_grad():  # Disable gradient calculation for validation\n","                    val_region_outputs = model({region_id:val_features})\n","                    val_output = val_region_outputs[region_id]\n","                    val_loss = criterion(val_output, val_targets)\n","                    validation_losses[region_id].append(val_loss.item())  # Store the loss in the dictionary\n","\n","                del val_features, val_targets, val_region_outputs  # Clear these variables\n","                pbar.update(1)  # Increment the outer progress bar by 1\n","\n","    return validation_losses  # Return losses for each region separately"]},{"cell_type":"code","execution_count":163,"metadata":{},"outputs":[],"source":["def hyperparameter_tuning(params,train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, neighbor_mask):\n","    checked_params_file = 'checkpoints/checked_params.json'  # Define the path for the checked parameters file\n","    checkpoint_path = 'checkpoints/working/model_checkpoint.pt'  # Define the path for the model checkpoint\n","\n","    # if os.path.exists(checked_params_file):\n","    #     with open(checked_params_file, 'r') as f:\n","    #         checked_params = json.load(f)  # Load as a dictionary\n","    # else:\n","    #     checked_params = {}  # Initialize an empty dictionary if no file exists\n","\n","    # if os.path.exists(checkpoint_path):\n","    #     checkpoint = torch.load(checkpoint_path)\n","    #     best_model = checkpoint['model']  # Load the best model\n","    #     best_params = checkpoint['params']  # Load the best parameters\n","        \n","    #     best_ind_validation_loss = checkpoint['indv_validation_loss']  # Load the best individual validation losses\n","    #     best_avg_validation_loss = checkpoint['avg_validation_loss']  # Load the best validation loss\n","\n","    checked_params = {}\n","    best_model = None\n","    best_params = None\n","    best_avg_validation_loss = float('inf')\n","\n","     # Iterate through each combination of hyperparameters\n","    for params in tqdm(ParameterGrid(params)):\n","        print(f\"Training with parameters: {params}\")\n","        params_key = json.dumps(params, sort_keys=True)  # Convert the parameters to a JSON string\n","\n","        if params_key in checked_params:\n","            continue  # Skip this combination if it has been checked\n","\n","        model = MultiRegionModel(neighbor_mask, input_size=input_size,\n","                        hidden_size=params['hidden_size'], num_layers=params['num_layers'], \n","                        output_size=1)  # output_size is fixed\n","\n","        # Initialize the model with the current parameters\n","        validation_losses = train_and_evaluate_model(\n","        model.to(device),\n","        train_features_dict, \n","        train_targets_dict, \n","        val_features_dict, \n","        val_targets_dict, \n","        params['learning_rate'],\n","        params['num_epochs']\n","    )\n","        checked_params[params_key] = validation_losses  # Store the validation loss for this combination\n","\n","        # Save the updated checked parameters dictionary to the file\n","        with open(checked_params_file, 'w') as f:\n","            json.dump(checked_params, f)\n","\n","        # Finds the validation loss for these parameters\n","        most_recent_losses = [losses[-1] for losses in validation_losses.values()]\n","        # Calculate the average validation loss\n","        overall_avg_loss = np.mean(most_recent_losses)\n","\n","\n","        # Update best model if the current one is better\n","        if overall_avg_loss < best_avg_validation_loss:\n","            best_avg_validation_loss = overall_avg_loss\n","            best_ind_validation_loss = most_recent_losses\n","            best_model = model\n","            best_params = params\n","            # Save the best model to a checkpoint\n","            torch.save({\n","                'model': best_model.state_dict(),  # Save the model state\n","                'params': best_params,  # Save the best parameters\n","                'indv_validation_loss': best_ind_validation_loss,  # Save the best individual validation losses\n","                'avg_validation_loss': best_avg_validation_loss  # Save the best average validation loss\n","            }, checkpoint_path)\n","\n","        # Clear the model from memory after saving\n","        del model\n","        \n","    print(f\"Best parameters: {best_params} with average validation loss: {best_avg_validation_loss}\")\n","    return best_model, best_ind_validation_loss, best_avg_validation_loss\n"]},{"cell_type":"markdown","metadata":{},"source":["We choose potential hyperparameters based on the values used by the various individual regions. This reduces the number of combinations we havve to check."]},{"cell_type":"code","execution_count":165,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef94395b915443dab610bf79a525b946","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Training with parameters: {'hidden_size': 8, 'learning_rate': 0.005, 'num_epochs': 10, 'num_layers': 2}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6289bbdecec44f4ab6403ceffb0dd65","version_major":2,"version_minor":0},"text/plain":["Processing Model:   0%|          | 0/110 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[165], line 12\u001b[0m\n\u001b[1;32m      3\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m16\u001b[39m],  \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m],      \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.005\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m],  \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m100\u001b[39m]         \n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m     10\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m best_model, best_ind_validation_loss, best_avg_validation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_features_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_features_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_targets_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneighbor_mask\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[163], line 37\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(params, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, neighbor_mask)\u001b[0m\n\u001b[1;32m     32\u001b[0m     model \u001b[38;5;241m=\u001b[39m MultiRegionModel(neighbor_mask, input_size\u001b[38;5;241m=\u001b[39minput_size,\n\u001b[1;32m     33\u001b[0m                     hidden_size\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m], num_layers\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     34\u001b[0m                     output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# output_size is fixed\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Initialize the model with the current parameters\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     validation_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_features_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_targets_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_features_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_targets_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     checked_params[params_key] \u001b[38;5;241m=\u001b[39m validation_losses  \u001b[38;5;66;03m# Store the validation loss for this combination\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;66;03m# Save the updated checked parameters dictionary to the file\u001b[39;00m\n","Cell \u001b[0;32mIn[162], line 43\u001b[0m, in \u001b[0;36mtrain_and_evaluate_model\u001b[0;34m(model, train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Backpropagation and optimization steps\u001b[39;00m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 43\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Validation step \u001b[39;00m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["batch_size=1\n","input_size=7\n","param_grid = {\n","    'hidden_size': [8,16],  \n","    'num_layers': [2,3],      \n","    'learning_rate': [0.005, 0.01, 0.05],  \n","    'num_epochs': [10,50,100]         \n","}\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","best_model, best_ind_validation_loss, best_avg_validation_loss = hyperparameter_tuning(param_grid,train_features_dict, train_targets_dict, val_features_dict, val_targets_dict, neighbor_mask)"]},{"cell_type":"markdown","metadata":{},"source":["Now we test the set on the same set as the individual models."]},{"cell_type":"code","execution_count":157,"metadata":{},"outputs":[],"source":["def test_full_model(test_features_dict,test_targets_dict):\n","    criterion = nn.MSELoss()\n","\n","    checkpoint_path = f'checkpoints/model_checkpoint.pt'  # Define the path for the checked parameters file\n","\n","    checkpoint = torch.load(checkpoint_path)\n","    best_params = checkpoint['params']\n","\n","    input_size = test_features_dict['region_0'].shape[2]\n","    hidden_size = best_params['hidden_size']\n","    num_layers = best_params['num_layers']\n","\n","    model = MultiRegionModel(neighbor_mask, input_size, hidden_size, num_layers, output_size=1)\n","    model.load_state_dict(checkpoint['model'])  # Load the best model\n","\n","    model.eval()  # Set model to evaluation mode\n","    test_losses = {}  # To store losses for each region\n","\n","    with torch.no_grad():  # Disable gradient calculation for testing\n","        for region_id, features in test_features_dict.items():\n","            targets = test_targets_dict[region_id]\n","            \n","            features = features.to(device)\n","            targets = targets.to(device)\n","\n","            # Forward pass: get the outputs for the region\n","            region_outputs = model({region_id: features})\n","            output = region_outputs[region_id]\n","\n","            # Compute loss\n","            loss = criterion(output, targets)\n","            test_losses[region_id] = {\"prediction\" : output, \"mean squared error\": loss.item()}  # Store the loss for this region\n","\n","    return test_losses  # Return losses for further analysis"]},{"cell_type":"code","execution_count":158,"metadata":{},"outputs":[],"source":["test_losses_dict = test_full_model(test_features_dict, test_targets_dict)"]},{"cell_type":"markdown","metadata":{},"source":["## Comparing preformance\n","\n","Now we compare the preformance of the individual regional models and the multiregional model."]},{"cell_type":"code","execution_count":161,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Region: region_0\n","  MSE Individual regions: 0.0017464500851929188\n","  MSE Multiple region model: 0.027798179537057877\n","  Difference: -0.026051729917526245\n","  Percentage Improvement: -1491.70%\n","  Better Model: Individual regions\n","Region: region_1\n","  MSE Individual regions: 0.009563806466758251\n","  MSE Multiple region model: 0.21470583975315094\n","  Difference: -0.2051420360803604\n","  Percentage Improvement: -2144.98%\n","  Better Model: Individual regions\n","Region: region_2\n","  MSE Individual regions: 0.01137600652873516\n","  MSE Multiple region model: 0.035362206399440765\n","  Difference: -0.023986199870705605\n","  Percentage Improvement: -210.85%\n","  Better Model: Individual regions\n","Region: region_3\n","  MSE Individual regions: 0.033262670040130615\n","  MSE Multiple region model: 0.03679642081260681\n","  Difference: -0.0035337507724761963\n","  Percentage Improvement: -10.62%\n","  Better Model: Individual regions\n","Region: region_4\n","  MSE Individual regions: 0.00023793429136276245\n","  MSE Multiple region model: 0.5515207052230835\n","  Difference: -0.5512827634811401\n","  Percentage Improvement: -231695.39%\n","  Better Model: Individual regions\n","Region: region_5\n","  MSE Individual regions: 0.0003617223701439798\n","  MSE Multiple region model: 0.024371614679694176\n","  Difference: -0.024009892717003822\n","  Percentage Improvement: -6637.66%\n","  Better Model: Individual regions\n","Region: region_6\n","  MSE Individual regions: 0.00033435403020121157\n","  MSE Multiple region model: 0.40322861075401306\n","  Difference: -0.4028942584991455\n","  Percentage Improvement: -120499.29%\n","  Better Model: Individual regions\n","Region: region_7\n","  MSE Individual regions: 0.0009532591211609542\n","  MSE Multiple region model: 0.004020518623292446\n","  Difference: -0.003067259443923831\n","  Percentage Improvement: -321.77%\n","  Better Model: Individual regions\n","Region: region_8\n","  MSE Individual regions: 0.0030452159699052572\n","  MSE Multiple region model: 0.30551400780677795\n","  Difference: -0.30246880650520325\n","  Percentage Improvement: -9932.59%\n","  Better Model: Individual regions\n","Region: region_9\n","  MSE Individual regions: 0.004979720804840326\n","  MSE Multiple region model: 0.005208616144955158\n","  Difference: -0.00022889534011483192\n","  Percentage Improvement: -4.60%\n","  Better Model: Individual regions\n","Region: region_10\n","  MSE Individual regions: 0.0025188501458615065\n","  MSE Multiple region model: 0.10706528276205063\n","  Difference: -0.1045464351773262\n","  Percentage Improvement: -4150.56%\n","  Better Model: Individual regions\n","\n","Average MSE Individual regions: 0.006216362584382296\n","Average MSE Multiple region model: 0.15596290931782938\n"]}],"source":["# Initialize variables for quantification\n","total_mse_indv_regions = 0\n","total_mse_all_regions = 0\n","count = 0\n","comparison_results = {}\n","\n","# Compare MSE for each region and quantify\n","for region_id in region_outputs_dict.keys():\n","    mse1 = region_outputs_dict[region_id]['mean squared error']\n","    mse2 = test_losses_dict[region_id]['mean squared error']\n","\n","    # Update totals for average calculation\n","    total_mse_indv_regions += mse1\n","    total_mse_all_regions += mse2\n","    count += 1\n","\n","    # Calculate metrics\n","    difference = mse1 - mse2\n","    percentage_improvement = ((mse1 - mse2) / mse1) * 100 if mse1 != 0 else None\n","\n","    comparison_results[region_id] = {\n","        'MSE Individual regions': mse1,\n","        'MSE Multiple region model': mse2,\n","        'Difference': difference,\n","        'Percentage Improvement': percentage_improvement,\n","        'Better Model': 'Individual regions' if mse1 < mse2 else 'Multiple region model'\n","    }\n","\n","# Calculate average MSE for both models\n","average_mse_model1 = total_mse_indv_regions / count if count > 0 else 0\n","average_mse_model2 = total_mse_all_regions / count if count > 0 else 0\n","\n","# Print the comparison results\n","for region_id, results in comparison_results.items():\n","    print(f\"Region: {region_id}\")\n","    print(f\"  MSE Individual regions: {results['MSE Individual regions']}\")\n","    print(f\"  MSE Multiple region model: {results['MSE Multiple region model']}\")\n","    print(f\"  Difference: {results['Difference']}\")\n","    print(f\"  Percentage Improvement: {results['Percentage Improvement']:.2f}%\")\n","    print(f\"  Better Model: {results['Better Model']}\")\n","\n","# Print average MSE for both models\n","print(f\"\\nAverage MSE Individual regions: {average_mse_model1}\")\n","print(f\"Average MSE Multiple region model: {average_mse_model2}\")\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
