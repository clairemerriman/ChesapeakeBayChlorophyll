{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1726749716803,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"B4cTM3ojIp06","outputId":"66365b7e-ecf3-4bd7-dbdb-f7da072a6de1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/ChesapeakeBay/ChesapeakeBayChlorophyll/notebooks/models\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","%cd /content/drive/MyDrive/ChesapeakeBay/ChesapeakeBayChlorophyll/notebooks/models"]},{"cell_type":"markdown","metadata":{"id":"NfAM04byIp09"},"source":["# Set up"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":5970,"status":"ok","timestamp":1726749724905,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"5lKH0EkzIp0-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import xarray as xr\n","import matplotlib.pyplot as plt\n","\n","\n","import logging\n","from tqdm import tqdm  # For progress bar\n","# Configure logging instead of print\n","logging.basicConfig(filename='tuning.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import contextlib\n","from concurrent.futures import ThreadPoolExecutor, as_completed"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Region 0: features tensor shape: torch.Size([2767, 5, 638]), chlorophyll tensor shape: torch.Size([2767, 638])\n","Region 1: features tensor shape: torch.Size([2767, 5, 450]), chlorophyll tensor shape: torch.Size([2767, 450])\n","Region 2: features tensor shape: torch.Size([2767, 5, 1472]), chlorophyll tensor shape: torch.Size([2767, 1472])\n","Region 3: features tensor shape: torch.Size([2767, 5, 1352]), chlorophyll tensor shape: torch.Size([2767, 1352])\n","Region 4: features tensor shape: torch.Size([2767, 5, 992]), chlorophyll tensor shape: torch.Size([2767, 992])\n","Region 5: features tensor shape: torch.Size([2767, 5, 975]), chlorophyll tensor shape: torch.Size([2767, 975])\n","Region 6: features tensor shape: torch.Size([2767, 5, 2856]), chlorophyll tensor shape: torch.Size([2767, 2856])\n","Region 7: features tensor shape: torch.Size([2767, 5, 486]), chlorophyll tensor shape: torch.Size([2767, 486])\n","Region 8: features tensor shape: torch.Size([2767, 5, 528]), chlorophyll tensor shape: torch.Size([2767, 528])\n","Region 9: features tensor shape: torch.Size([2767, 5, 646]), chlorophyll tensor shape: torch.Size([2767, 646])\n","Region 10: features tensor shape: torch.Size([2767, 5, 1242]), chlorophyll tensor shape: torch.Size([2767, 1242])\n"]}],"source":["# Load tensors\n","# features_tensor = torch.load('../../data/features_masked_tensor.pt')\n","# chlorophyll_tensor = torch.load('../../data/chlorophyll_masked_tensor.pt')\n","\n","features_tensor_dict = {}\n","\n","for i in range(11):\n","    # Load tensors using formatted string (f-string)\n","    features_tensor = torch.load(f'../../data/filesForModel/tensors/features_region{i}_tensor.pt')\n","    chlorophyll_tensor = torch.load(f'../../data/filesForModel/tensors/chlorophyll_region{i}_tensor.pt')\n","\n","    # # Attach names to tensor dimensions\n","    # features_tensor.names = ('time','features','position')\n","    # chlorophyll_tensor.names = ('time','position')\n","\n","    # Store the tensors in the dictionary\n","    features_tensor_dict[f'region_{i}_features'] = features_tensor\n","    features_tensor_dict[f'region_{i}_chlorophyll'] = chlorophyll_tensor\n","\n","    print(f\"Region {i}: features tensor shape: {features_tensor.shape}, chlorophyll tensor shape: {chlorophyll_tensor.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"elw_9KwpIp1D"},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["We will create create a data stream for each of the 11 regions. Within each of these regions, we use a long short-term memory model (LSTM) to predict the chlorophyll values at each point."]},{"cell_type":"markdown","metadata":{"id":"1JjbhYbjIp1D"},"source":["## Defining the classes"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"TqW4f2jxIp1D"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class RegionalLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size,h0=None, c0=None):\n","        super(RegionalLSTM, self).__init__()\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","\n","        # Store hidden states if needed\n","        self.h0 = h0\n","        self.c0 = c0\n","    def forward(self, x, h0=None, c0=None, time_batch_size= 100):\n","        # x shape: (batch_size, time_steps, variables, position)\n","\n","        batch_size, time_steps, variables, positions = x.size()\n","        \n","        # Reshape to (batch_size * position, time_steps, variables) to treat each position separately\n","        x = x.permute(0, 3, 1, 2).reshape(batch_size * positions, time_steps, variables)\n","        \n","        # If no hidden state provided, initialize hidden states\n","        if h0 is None or c0 is None:\n","            h0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","            c0 = torch.zeros(self.lstm.num_layers, x.size(0), self.lstm.hidden_size).to(x.device)\n","\n","\n","        # Adjust mini-batching to handle cases where time_steps < time_batch_size\n","        outputs = []\n","        for start in range(0, time_steps, time_batch_size):\n","            end = min(start + time_batch_size, time_steps)\n","            x_time_batch = x[:, start:end, :]  # Mini-batch along time\n","            \n","            # Forward pass through the LSTM with hidden state carryover\n","            lstm_out, (h0, c0) = self.lstm(x_time_batch, (h0, c0))  # Keep hidden state across time mini-batches\n","            \n","            outputs.append(lstm_out)\n","        \n","        # Concatenate the outputs for all time mini-batches\n","        lstm_out = torch.cat(outputs, dim=1)  # Concatenate along the time dimension\n","        \n","        # Apply the fully connected layer at every time step for each position\n","        out = self.fc(lstm_out)  # Shape: (batch_size * positions, time_steps, output_size)\n","        \n","        # Reshape back to (batch_size, time_steps, variables, positions)\n","        out = out.view(batch_size, positions, time_steps).permute(0, 2, 1)\n","        \n","        return out, (h0,c0)\n"]},{"cell_type":"markdown","metadata":{},"source":["Since the relationship between regions comes from a map, we will hard code the data. Simply using a 1 if the regions border each other and 0 if they do not."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Neighbor mask matrix (as described earlier)\n","neighbor_mask = torch.tensor([\n","    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # Region 1, CB1TF\n","    [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],  # Region 2, CB2OH\n","    [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # Region 3, CB3MH\n","    [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],  # Region 4, CB4MH\n","    [0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1],  # Region 5, CB5MH\n","    [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0],  # Region 6, CB6PH\n","    [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],  # Region 7, CB7PH\n","    [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],  # Region 8, CB8PH\n","    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],  # Region 9, EASMH\n","    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],  # Region 10, MOBPH\n","    [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]   # Region 11, TANMH\n","], dtype=torch.float32)"]},{"cell_type":"markdown","metadata":{},"source":["# All regions?"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Region 0: Train features torch.Size([1, 1936, 5, 638]), Validation features torch.Size([1, 415, 5, 638]), Test features torch.Size([1, 416, 5, 638])\n","Region 0: Train targets torch.Size([1, 1936, 638]), Validation targets torch.Size([1, 415, 638]), Test targets torch.Size([1, 416, 638])\n","Region 1: Train features torch.Size([1, 1936, 5, 450]), Validation features torch.Size([1, 415, 5, 450]), Test features torch.Size([1, 416, 5, 450])\n","Region 1: Train targets torch.Size([1, 1936, 450]), Validation targets torch.Size([1, 415, 450]), Test targets torch.Size([1, 416, 450])\n","Region 2: Train features torch.Size([1, 1936, 5, 1472]), Validation features torch.Size([1, 415, 5, 1472]), Test features torch.Size([1, 416, 5, 1472])\n","Region 2: Train targets torch.Size([1, 1936, 1472]), Validation targets torch.Size([1, 415, 1472]), Test targets torch.Size([1, 416, 1472])\n","Region 3: Train features torch.Size([1, 1936, 5, 1352]), Validation features torch.Size([1, 415, 5, 1352]), Test features torch.Size([1, 416, 5, 1352])\n","Region 3: Train targets torch.Size([1, 1936, 1352]), Validation targets torch.Size([1, 415, 1352]), Test targets torch.Size([1, 416, 1352])\n","Region 4: Train features torch.Size([1, 1936, 5, 992]), Validation features torch.Size([1, 415, 5, 992]), Test features torch.Size([1, 416, 5, 992])\n","Region 4: Train targets torch.Size([1, 1936, 992]), Validation targets torch.Size([1, 415, 992]), Test targets torch.Size([1, 416, 992])\n","Region 5: Train features torch.Size([1, 1936, 5, 975]), Validation features torch.Size([1, 415, 5, 975]), Test features torch.Size([1, 416, 5, 975])\n","Region 5: Train targets torch.Size([1, 1936, 975]), Validation targets torch.Size([1, 415, 975]), Test targets torch.Size([1, 416, 975])\n","Region 6: Train features torch.Size([1, 1936, 5, 2856]), Validation features torch.Size([1, 415, 5, 2856]), Test features torch.Size([1, 416, 5, 2856])\n","Region 6: Train targets torch.Size([1, 1936, 2856]), Validation targets torch.Size([1, 415, 2856]), Test targets torch.Size([1, 416, 2856])\n","Region 7: Train features torch.Size([1, 1936, 5, 486]), Validation features torch.Size([1, 415, 5, 486]), Test features torch.Size([1, 416, 5, 486])\n","Region 7: Train targets torch.Size([1, 1936, 486]), Validation targets torch.Size([1, 415, 486]), Test targets torch.Size([1, 416, 486])\n","Region 8: Train features torch.Size([1, 1936, 5, 528]), Validation features torch.Size([1, 415, 5, 528]), Test features torch.Size([1, 416, 5, 528])\n","Region 8: Train targets torch.Size([1, 1936, 528]), Validation targets torch.Size([1, 415, 528]), Test targets torch.Size([1, 416, 528])\n","Region 9: Train features torch.Size([1, 1936, 5, 646]), Validation features torch.Size([1, 415, 5, 646]), Test features torch.Size([1, 416, 5, 646])\n","Region 9: Train targets torch.Size([1, 1936, 646]), Validation targets torch.Size([1, 415, 646]), Test targets torch.Size([1, 416, 646])\n","Region 10: Train features torch.Size([1, 1936, 5, 1242]), Validation features torch.Size([1, 415, 5, 1242]), Test features torch.Size([1, 416, 5, 1242])\n","Region 10: Train targets torch.Size([1, 1936, 1242]), Validation targets torch.Size([1, 415, 1242]), Test targets torch.Size([1, 416, 1242])\n"]}],"source":["train_features_dict = {}\n","val_features_dict = {}\n","test_features_dict = {}\n","train_targets_dict = {}\n","val_targets_dict = {}\n","test_targets_dict = {}\n","\n","# feature shape (time, variables, position)\n","# chlorophyll shape (time, position)\n","for region_id in range(11):\n","    # Access the features and chlorophyll tensors from the dictionary\n","    features_tensor = features_tensor_dict[f'region_{region_id}_features']\n","    chlorophyll_tensor = features_tensor_dict[f'region_{region_id}_chlorophyll']\n","\n","    # reshape to (batch, time, variables, position)\n","    features_tensor = features_tensor.unsqueeze(0)\n","    chlorophyll_tensor = chlorophyll_tensor.unsqueeze(0)\n","    \n","    # Split data into 70% training, 15% validation, 15% test\n","    train_size = int(0.7 * features_tensor.shape[1])  # 70% of the time steps\n","    val_size = int(0.15 * features_tensor.shape[1])   # 15% for validation\n","    test_size = features_tensor.shape[1] - train_size - val_size  # Remaining for test set\n","\n","    # Split features into train, validation, and test sets\n","    train_features = features_tensor[:, :train_size, :, :]  # First 70% for training\n","    val_features = features_tensor[:, train_size:train_size+val_size, :, :]  # Next 15% for validation\n","    test_features = features_tensor[:, train_size+val_size:, :, :]  # Remaining for test\n","    \n","    # Split chlorophyll targets (same logic)\n","    train_targets = chlorophyll_tensor[:, :train_size, :]  # First 70% for training\n","    val_targets = chlorophyll_tensor[:, train_size:train_size+val_size, :]  # Next 15% for validation\n","    test_targets = chlorophyll_tensor[:, train_size+val_size:, :]  # Remaining for test\n","\n","    # Store the splits in dictionaries\n","    # Also correct the indexing\n","    train_features_dict[f'region_{region_id}'] = train_features\n","    val_features_dict[f'region_{region_id}'] = val_features\n","    test_features_dict[f'region_{region_id}'] = test_features\n","    \n","    train_targets_dict[f'region_{region_id}'] = train_targets\n","    val_targets_dict[f'region_{region_id}'] = val_targets\n","    test_targets_dict[f'region_{region_id}'] = test_targets\n","\n","    # Print shapes for verification\n","    print(f\"Region {region_id}: Train features {train_features.shape}, Validation features {val_features.shape}, Test features {test_features.shape}\")\n","    print(f\"Region {region_id}: Train targets {train_targets.shape}, Validation targets {val_targets.shape}, Test targets {test_targets.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = RegionalLSTM(input_size=6, hidden_size=8, num_layers=1, output_size=1)\n","criterion = nn.MSELoss()  # Assuming you are using Mean Squared Error for regression\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","# Training parameters\n","epochs = 5\n","batch_size = 1\n","\n","for i in tqdm(range(11),desc=f\"Modelling all regions\"):\n","    # Convert the train_features and train_targets to the appropriate device\n","    train_features = train_features_dict[f'region_{i}'].to(device)\n","    train_targets = train_targets_dict[f'region_{i}'].to(device)\n","\n","    for epoch in tqdm(range(epochs),desc=f\"Model for Region {i}\"):\n","        model.train()  # Set model to training mode\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        output, _ = model(train_features)\n","\n","        # Compute the loss\n","        loss = criterion(output, train_targets)\n","\n","        # Backward pass and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}\")\n","\n","    # Validation step \n","    model.eval()  # Set model to evaluation mode\n","    val_features = val_features_dict[f'region_{i}'].to(device)\n","    val_targets = val_targets_dict[f'region_{i}'].to(device)\n","\n","    with torch.no_grad():  # Disable gradient calculation for validation\n","        val_output, _ = model(val_features)\n","        val_loss = criterion(val_output, val_targets)\n","        print(f\"Validation Loss: {val_loss.item()}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Try sharing"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class MultiRegionModel(nn.Module):\n","    def __init__(self, neighbor_mask, input_size, hidden_size, num_layers, output_size):\n","        super(MultiRegionModel, self).__init__()\n","        self.neighbor_mask = neighbor_mask\n","        self.regions = nn.ModuleList([\n","            RegionalLSTM(input_size, hidden_size, num_layers, output_size) \n","            for _ in range(neighbor_mask.shape[0])\n","        ])\n","\n","\n","    def forward(self, region_inputs):\n","        # region_inputs should be a dictionary where keys are region IDs and values are feature tensors\n","        region_outputs = {}  # Initialize a dictionary to store outputs for each region\n","\n","        for region_id, region_data in region_inputs.items():\n","            # Assuming region_id can be converted to an index\n","            region_index = int(region_id[-1]) \n","            # Initialize combined_h0 for the first pass\n","            position_size = region_data.shape[-1]\n","            current_h0 = torch.zeros((batch_size, position_size, self.regions[region_index].lstm.hidden_size))  # Replace with appropriate shape\n","            \n","            # Find neighbors\n","            neighbors = [i for i in range(1, self.neighbor_mask.shape[0] ) if self.neighbor_mask[region_index, i] == 1]\n","            \n","            neighbor_hidden_states = []\n","            for neighbor_index in neighbors:\n","                _, (neighbor_h0, neighbor_c0) = self.regions[neighbor_index](region_data)  # Use region_data for the neighbor\n","\n","                neighbor_hidden_states.append(neighbor_h0)\n","                # Assuming neighbor_hidden_states is a list of (batch_size * positions, time_steps, hidden_size) tensors\n","            if neighbor_hidden_states:\n","                aggregated_neighbors_h0 = torch.mean(torch.stack(neighbor_hidden_states), dim=0)  # Mean across neighbors\n","\n","            # Combine current hidden state with aggregated neighbor hidden states\n","            combined_h0 = current_h0 + F.interpolate(aggregated_neighbors_h0, size=current_h0.shape[-1], mode='linear', align_corners=False)\n","            # Adjust this operation as needed\n","\n","            # Call the RegionalLSTM with the current input and updated hidden states\n","            output, (current_h0, current_c0) = self.regions[region_index](region_data, combined_h0, neighbor_c0)\n","\n","            # Store the output for the current region\n","            region_outputs[region_id] = output# Store the output for the current region\n","        return region_outputs  # Return the dictionary of outputs for each region\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Regions in epoch 0: 100%|██████████| 11/11 [01:23<00:00,  7.58s/it]\n"]}],"source":["epochs = 1\n","batch_size=1\n","input_size=5\n","hidden_size=2\n","num_layers=2\n","#  Initialize the model\n","model = MultiRegionModel(neighbor_mask,input_size, hidden_size, num_layers, output_size=1)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()  # Mean Squared Error for regression\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","last_outputs_dict = {region_id: [] for region_id in train_features_dict.keys()}\n","validation_losses = {region_id: [] for region_id in val_features_dict.keys()}\n","\n","for epoch in range(epochs):\n","    # Create a progress bar for epochs\n","    \n","    # Wrap the region_inputs dictionary with tqdm for progress tracking\n","    with tqdm(total=len(train_features_dict), desc=f\"Processing Regions in epoch {epoch}\",leave=True) as inner_pbar:\n","        for region_id, features in train_features_dict.items():\n","\n","            targets = train_targets_dict[region_id]\n","            \n","            # Forward pass: get the outputs for all regions\n","            region_outputs = model({region_id: features})\n","            \n","            # Retrieve output for the specific region\n","            output = region_outputs[region_id]\n","            \n","            # Store for SHAP \n","            last_outputs_dict[region_id].append(output.detach().cpu().numpy())  # Detach and move to CPU if necessary\n","\n","            # Compute loss\n","            loss = criterion(output, targets)\n","\n","            # Backpropagation and optimization steps\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            inner_pbar.update(1)  # Increment the inner progress bar by 1\n","\n","            # Validation step \n","            model.eval()  # Set model to evaluation mode\n","            val_features = val_features_dict[f'region_{i}'].to(device)\n","            val_targets = val_targets_dict[f'region_{i}'].to(device)\n","\n","            with torch.no_grad():  # Disable gradient calculation for validation\n","                val_region_outputs = model({region_id:val_features})\n","                val_output = val_region_outputs[region_id]\n","                val_loss = criterion(val_output, val_targets)\n","                validation_losses[region_id].append(val_loss.item())  # Store the loss in the dictionary\n","\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[],"source":["# After training, you can concatenate the outputs for SHAP analysis\n","for region_id, outputs in last_outputs_dict.items():\n","    last_outputs_dict[region_id] = np.concatenate(outputs, axis=0)  # Combine outputs across epochs if needed\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reshape for SHAP\n","reshaped_region_diict = {}\n","\n","for region_id, region_data in train_features_dict.item():\n","    # Example: Aggregate across the position dimension by averaging\n","    aggregated_data = region_data.mean(dim=3).squeeze(0)  # Shape becomes (time, features)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import shap\n","\n","def regional_lstm_predict(region_id, input_data):\n","    region_model = multi_region_model.regions[region_id]  # Access specific RegionalLSTM\n","    with torch.no_grad():\n","        return region_model(input_data).numpy()  # Ensure input_data is in correct shape\n","\n","# Create the SHAP explainer using the aggregated input data\n","explainer = shap.KernelExplainer(lambda x: regional_lstm_predict(region_id, x), reshaped_data)\n","\n","# Calculate SHAP values\n","shap_values = explainer.shap_values(reshaped_data)\n","\n","# Visualize the SHAP values\n","shap.summary_plot(shap_values, reshaped_data)\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"data":{"text/plain":["{'region_0': [0.34159421920776367,\n","  0.3092031180858612,\n","  0.2811068892478943,\n","  0.256698876619339,\n","  0.23560895025730133,\n","  0.21779844164848328,\n","  0.20326048135757446,\n","  0.1919095814228058,\n","  0.18349026143550873,\n","  0.1774870753288269],\n"," 'region_1': [0.18052701652050018,\n","  0.1787278652191162,\n","  0.179288849234581,\n","  0.18036194145679474,\n","  0.18066148459911346,\n","  0.17955242097377777,\n","  0.177238330245018,\n","  0.17391307651996613,\n","  0.16899029910564423,\n","  0.16104598343372345],\n"," 'region_2': [0.5430854558944702,\n","  0.44662365317344666,\n","  0.36399152874946594,\n","  0.29452139139175415,\n","  0.23653288185596466,\n","  0.19088152050971985,\n","  0.16162890195846558,\n","  0.14997661113739014,\n","  0.1464603692293167,\n","  0.14033474028110504],\n"," 'region_3': [1.052377462387085,\n","  0.9826801419258118,\n","  0.9204058647155762,\n","  0.8636765480041504,\n","  0.8112435340881348,\n","  0.7619773745536804,\n","  0.7145645618438721,\n","  0.6674513220787048,\n","  0.6189589500427246,\n","  0.5676072835922241],\n"," 'region_4': [0.1743701845407486,\n","  0.17460380494594574,\n","  0.1755693256855011,\n","  0.17734448611736298,\n","  0.18007954955101013,\n","  0.1838657408952713,\n","  0.1886148750782013,\n","  0.1941976398229599,\n","  0.2000647932291031,\n","  0.20494160056114197],\n"," 'region_5': [0.7968912720680237,\n","  0.7254034280776978,\n","  0.6630971431732178,\n","  0.606262743473053,\n","  0.5532981157302856,\n","  0.5032255053520203,\n","  0.45543333888053894,\n","  0.40958502888679504,\n","  0.3655685782432556,\n","  0.3234676718711853],\n"," 'region_6': [0.16957420110702515,\n","  0.1601281762123108,\n","  0.1499658077955246,\n","  0.13896210491657257,\n","  0.1273423135280609,\n","  0.1161210760474205,\n","  0.1043732687830925,\n","  0.08913014084100723,\n","  0.07124195992946625,\n","  0.05349717661738396],\n"," 'region_7': [0.3270117938518524,\n","  0.29714444279670715,\n","  0.2690218687057495,\n","  0.2435724437236786,\n","  0.2209204137325287,\n","  0.20105265080928802,\n","  0.18412119150161743,\n","  0.1704535186290741,\n","  0.16030055284500122,\n","  0.15349391102790833],\n"," 'region_8': [1.147547960281372,\n","  1.04667329788208,\n","  0.9594937562942505,\n","  0.8859505653381348,\n","  0.8240069150924683,\n","  0.7714418172836304,\n","  0.726314902305603,\n","  0.6870656609535217,\n","  0.6524835228919983,\n","  0.621645987033844],\n"," 'region_9': [0.4441354274749756,\n","  0.3805042505264282,\n","  0.33111417293548584,\n","  0.2928907573223114,\n","  0.26310035586357117,\n","  0.23987360298633575,\n","  0.22188982367515564,\n","  0.20815424621105194,\n","  0.19786860048770905,\n","  0.19036053121089935],\n"," 'region_10': [0.3246396780014038,\n","  0.2944466173648834,\n","  0.26827073097229004,\n","  0.2455390989780426,\n","  0.22609077394008636,\n","  0.2099248617887497,\n","  0.1970069855451584,\n","  0.18718257546424866,\n","  0.18007352948188782,\n","  0.17503339052200317]}"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["validation_losses"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["output"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
