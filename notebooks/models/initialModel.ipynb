{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22586,"status":"ok","timestamp":1726743604530,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"B4cTM3ojIp06","outputId":"b1d3c11f-b111-4421-bc17-f02ac592c2bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","/content/drive/MyDrive/ChesapeakeBay/notebooks/models\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","%cd /content/drive/MyDrive/ChesapeakeBay/notebooks/models"]},{"cell_type":"markdown","metadata":{"id":"NfAM04byIp09"},"source":["# Set up"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8380,"status":"ok","timestamp":1726743612907,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"5lKH0EkzIp0-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import datetime\n","import xarray as xr\n","import matplotlib.pyplot as plt\n","\n","\n","import logging\n","from tqdm import tqdm  # For progress bar\n","# Configure logging instead of print\n","logging.basicConfig(filename='tuning.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","import itertools\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.optim as optim\n","import contextlib\n","from concurrent.futures import ThreadPoolExecutor, as_completed"]},{"cell_type":"markdown","metadata":{"id":"6cvfG495Ip0_"},"source":["# Input and shape the data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"3kikXqoeIp0_","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"error","timestamp":1726743621376,"user_tz":240,"elapsed":8482,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}},"outputId":"e09296e6-2d3b-42b2-93c8-93b4207cf5e5"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: [<class 'h5netcdf.core.File'>, ('/content/drive/MyDrive/ChesapeakeBay/data/satelliteBuoy_clean.nc4',), 'r', (('decode_vlen_strings', True), ('driver', None), ('invalid_netcdf', None)), '7d74dd96-9812-4bf1-b725-94571f74ee8e']","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-b747e36e6b0b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msatellite_buoy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/satelliteBuoy_clean.nc4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, format, group, lock, invalid_netcdf, phony_dims, decode_vlen_strings, driver, driver_kwds)\u001b[0m\n\u001b[1;32m    404\u001b[0m     ) -> Dataset:\n\u001b[1;32m    405\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m         store = H5NetCDFStore.open(\n\u001b[0m\u001b[1;32m    407\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, lock, autoclose, invalid_netcdf, phony_dims, decode_vlen_strings, driver, driver_kwds)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mmanager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCachingFileManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5netcdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# todo: utilizing find_root_and_group seems a bit clunky\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#  making filename available on h5netcdf.Group seems better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_root_and_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/h5netcdf_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             ds = _nc4_require_group(\n\u001b[1;32m    189\u001b[0m                 \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_h5netcdf_create_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5netcdf/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, invalid_netcdf, phony_dims, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;31m# This maps keeps track of all HDF5 datasets corresponding to this group.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_h5groups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChainMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h5group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h5path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# get maximum dimension id and count of labeled dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5netcdf/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, name)\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mphony_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h5group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_h5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;31m# add to the groups collection if this is a h5py(d) Group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/base.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reversed__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name, default, getclass, getlink)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgetclass\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mgetlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             raise TypeError(\"Accessing a group is done with bytes or str, \"\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5i.pyx\u001b[0m in \u001b[0;36mh5py.h5i.wrap_identifier\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["satellite_buoy = xr.open_dataset('../../data/satelliteBuoy_clean.nc4')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1726743621377,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"IYZjIwNoIp1A"},"outputs":[],"source":["satellite_buoy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1726743621377,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"ea3kMohTIp1B"},"outputs":[],"source":["satellite_buoy.data_vars"]},{"cell_type":"markdown","metadata":{"id":"zwjTxnE0Ip1B"},"source":["We need to make sure the timesteps are in order."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1726743621377,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"Ag0zPuoUIp1C"},"outputs":[],"source":["# Check if the time dimension is sorted\n","is_sorted = (satellite_buoy['time'].values == sorted(satellite_buoy['time'].values)).all()\n","\n","if is_sorted:\n","    print(\"The time steps are already in order.\")\n","else:\n","    print(\"The time steps are not in order.\")\n"]},{"cell_type":"markdown","metadata":{"id":"p69qiDS6gZ_Z"},"source":["We want to target the chorophyll measurements and use Air Temperature, Air pressure, Humidity, Wind speed, and Wind Direction as features. Let's create the target and features tensor, then save the files for use on the GPU. Since `xarray` is on CPU, this step is MUCH faster on CPU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLSWlp5MIp1D","executionInfo":{"status":"aborted","timestamp":1726743621377,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Define the variables to be concatenated into features\n","variables_to_expand = ['Air Temperature', 'Air pressure', 'Humidity', 'Wind speed', 'Wind Direction']\n","\n","# Convert xarray combined features to a PyTorch tensor (on CPU)\n","features = xr.concat([satellite_buoy[var] for var in variables_to_expand], dim='variable')\n","features_tensor = torch.tensor(features.values, dtype=torch.float32)\n","\n","# Rearrange the dimensions to match ConvLSTM input format: (time_steps, features, depth, lat, lon)\n","features_tensor = features_tensor.permute(1, 0, 2, 3, 4)\n","\n","# Convert 'chlor_a' to a PyTorch tensor (target) and add depth dimension if needed\n","chlorophyll_tensor = torch.tensor(satellite_buoy['chlor_a'].values, dtype=torch.float32)\n","\n","# Replace NaN values with -1\n","chlorophyll_tensor[torch.isnan(chlorophyll_tensor)] = -1\n","\n","# Now save both tensors as .pt files for later use\n","torch.save(features_tensor, '../../data/features_tensor.pt')\n","torch.save(chlorophyll_tensor, '../../data/chlorophyll_tensor.pt')\n","\n","# Optional: Print shapes to confirm\n","print(f\"Features tensor shape: {features_tensor.shape}\")\n","print(f\"Chlorophyll tensor shape: {chlorophyll_tensor.shape}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78175,"status":"ok","timestamp":1726743704465,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"cbEyRKCTgZ_a","outputId":"63aacf2c-45b6-42af-d3a4-9247e48e9c84"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-3edfe1997d64>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  features_tensor = torch.load('../../data/features_tensor.pt')\n","<ipython-input-4-3edfe1997d64>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  chlorophyll_tensor = torch.load('../../data/chlorophyll_tensor.pt')\n"]},{"output_type":"stream","name":"stdout","text":["Loaded Features tensor shape: torch.Size([2767, 5, 1, 358, 243])\n","Loaded Chlorophyll tensor shape: torch.Size([2767, 1, 358, 243])\n"]}],"source":["# Load tensors\n","features_tensor = torch.load('../../data/features_tensor.pt')\n","chlorophyll_tensor = torch.load('../../data/chlorophyll_tensor.pt')\n","\n","# Optional: Print shapes to confirm\n","print(f\"Loaded Features tensor shape: {features_tensor.shape}\")\n","print(f\"Loaded Chlorophyll tensor shape: {chlorophyll_tensor.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"elw_9KwpIp1D"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"1JjbhYbjIp1D"},"source":["## Defining the classes"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1726743704465,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"TqW4f2jxIp1D"},"outputs":[],"source":["class ConvLSTMCell(nn.Module):\n","    # For one time slice\n","    # input has shape (batch_size, features, depth, latitude, longitude)\n","    def __init__(self, input_channels, hidden_channels, kernel_size):\n","        super(ConvLSTMCell, self).__init__()\n","        padding = kernel_size // 2\n","        self.conv = nn.Conv3d(input_channels + hidden_channels,\n","                              hidden_channels * 4,  # 4 for i, f, o, g gates\n","                              kernel_size,\n","                              padding=padding)\n","\n","    def forward(self, input_tensor, hidden_state):\n","        h_cur, c_cur = hidden_state\n","\n","        # Concatenate input and hidden state\n","        combined = torch.cat([input_tensor, h_cur], dim=1).contiguous()\n","\n","        conv_output = self.conv(combined)\n","\n","        cc_i, cc_f, cc_o, cc_g = torch.split(conv_output, conv_output.shape[1] // 4, dim=1)\n","\n","        i = torch.sigmoid(cc_i)\n","        f = torch.sigmoid(cc_f)\n","        o = torch.sigmoid(cc_o)\n","        g = torch.tanh(cc_g)\n","\n","        c_next = f * c_cur + i * g\n","        h_next = o * torch.tanh(c_next)\n","\n","        return h_next, c_next"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726743704465,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"AoQrWWSzIp1E"},"outputs":[],"source":["class ConvLSTM(nn.Module):\n","    def __init__(self, input_channels, hidden_channels, kernel_size, num_layers, output_channels=1):\n","        super(ConvLSTM, self).__init__()\n","        self.num_layers = num_layers\n","        self.hidden_channels = hidden_channels\n","\n","        # Define a list of ConvLSTM cells\n","        self.lstm_cells = nn.ModuleList([\n","            ConvLSTMCell(input_channels if i == 0 else hidden_channels,  # First layer uses input channels, others use hidden channels\n","                         hidden_channels,\n","                         kernel_size)\n","            for i in range(num_layers)\n","        ])\n","\n","\n","        self.conv = nn.Conv3d(in_channels=hidden_channels, out_channels=1, kernel_size=1)\n","\n","\n","    def forward(self, input_tensor, time_step_batch_size=10):\n","        # if no batch_size dimension, add one\n","        if len(input_tensor.shape) == 5:\n","            input_tensor = input_tensor.unsqueeze(0)\n","\n","        batch_size, time_steps, channels, depth, height, width = input_tensor.size()\n","        h, c = self.init_hidden(batch_size, depth, height, width, input_tensor.device)\n","\n","        output_inner = []\n","\n","        # Process time steps in batches\n","        for t in range(0, time_steps, time_step_batch_size):\n","            # Select a batch of time steps to process\n","            time_step_batch = input_tensor[:, t:t + time_step_batch_size, :, :, :, :]\n","            for t_batch in range(time_step_batch.size(1)):  # Iterate over the time step batch\n","                x = time_step_batch[:, t_batch, :, :, :, :]  # Start with the input tensor\n","                for i, cell in enumerate(self.lstm_cells):\n","                    h[i], c[i] = cell(x, (h[i], c[i]))  # Pass hidden state to the next layer\n","                    x = h[i]  # The output of this layer becomes input for the next layer\n","\n","\n","\n","                output_inner.append(h[-1])  # Save the output from the final layer\n","\n","        output = torch.stack(output_inner, dim=1)  # Stack outputs across time steps\n","        output = output.squeeze(0)  # Remove the batch dimension to get (time, hidden_channels, depth, lat, lon)\n","        # Turn hidden_layers into a predicted value\n","        final_output = self.conv(output)\n","\n","\n","        return final_output\n","\n","    # Define hidden state initialization\n","    def init_hidden(self, batch_size, depth, height, width, device):\n","        h = [torch.zeros(batch_size, self.hidden_channels, depth, height, width).to(device) for _ in range(self.num_layers)]\n","        c = [torch.zeros(batch_size, self.hidden_channels, depth, height, width).to(device) for _ in range(self.num_layers)]\n","        return h, c\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726743704465,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"10XMsEGSIp1F"},"outputs":[],"source":["class HyperparameterTuner:\n","    def __init__(self, input_channels, train_data, val_data, criterion, device):\n","        self.input_channels = input_channels\n","        self.train_features, self.train_targets = train_data\n","        self.val_features, self.val_targets = val_data\n","        self.criterion = criterion\n","        self.device = device\n","\n","    def build_model(self, hidden_channels, kernel_size, num_layers):\n","        model = ConvLSTM(\n","            input_channels=self.input_channels,\n","            hidden_channels=hidden_channels,\n","            kernel_size=kernel_size,\n","            num_layers=num_layers\n","        ).to(self.device)\n","        return model\n","\n","    def _run_one_epoch(self, model, features, targets, optimizer, scaler, training=True):\n","        # Set model mode: training or evaluation\n","        model.train() if training else model.eval()\n","\n","        # Use autocast and gradients only if running on a GPU\n","        use_cuda = torch.cuda.is_available()\n","        with torch.set_grad_enabled(training), (torch.cuda.amp.autocast() if use_cuda else contextlib.nullcontext()):\n","            output = model(features)\n","            predicted_output = output[:, 0, :, :, :]  # Select the first hidden channel\n","            loss = self.criterion(predicted_output, targets)\n","\n","        # Backward pass and optimization (only during training)\n","        if training:\n","            optimizer.zero_grad()  # Zero out gradients before backward pass\n","            if use_cuda and scaler:\n","                scaler.scale(loss).backward()  # Backward pass with mixed precision scaling\n","                scaler.step(optimizer)\n","                scaler.update()  # Update the scaler for AMP\n","            else:\n","                loss.backward()\n","                optimizer.step()\n","\n","        return loss.item()\n","\n","    def _train_single_config(self, hidden_channels, kernel_size, num_layers, lr, epochs, pbar):\n","        # Build the model\n","        model = self.build_model(hidden_channels, kernel_size, num_layers)\n","\n","        # Ensure model is moved to the correct device (CPU or GPU)\n","        model = model.to(self.device)\n","\n","        # Set up the optimizer\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","        # Train the model and capture losses\n","        train_losses, val_losses = self.train(model, optimizer, epochs)\n","\n","        # Free up memory manually after each model is trained\n","        torch.cuda.empty_cache()  # Free memory if on GPU\n","\n","        # Update progress bar\n","        pbar.update(1)\n","\n","        return val_losses[-1], hidden_channels, kernel_size, num_layers, lr, model\n","\n","    def train(self, model, optimizer, epochs, early_stopping_patience=5):\n","        train_losses = []\n","        val_losses = []\n","        best_val_loss = float('inf')\n","        patience_counter = 0\n","\n","        # Initialize mixed precision scaler only if GPU is available\n","        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n","\n","\n","        for epoch in range(epochs):\n","            # TRAINING PHASE\n","            train_loss = self._run_one_epoch(model, self.train_features, self.train_targets, optimizer, scaler, training=True)\n","            train_losses.append(train_loss)\n","\n","            # VALIDATION PHASE\n","            val_loss = self._run_one_epoch(model, self.val_features, self.val_targets, optimizer, scaler, training=False)\n","            val_losses.append(val_loss)\n","\n","            # Check for early stopping\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                patience_counter = 0\n","            else:\n","                patience_counter += 1\n","\n","            if patience_counter >= early_stopping_patience:\n","                print(\"Early stopping triggered.\")\n","                break\n","\n","        return train_losses, val_losses\n","\n","    def tune(self, hidden_channels_list, kernel_size_list, num_layers_list, lr_list, epochs=5):\n","        best_val_loss = float('inf')\n","        best_config = None\n","        best_model = None\n","\n","        # Create the product of all hyperparameter combinations\n","        hyperparameter_combinations = list(itertools.product(\n","            hidden_channels_list, kernel_size_list, num_layers_list, lr_list\n","        ))\n","\n","        # Initialize the progress bar\n","        with tqdm(total=len(hyperparameter_combinations), desc=\"Hyperparameter Tuning\", leave=True) as pbar:\n","            with ThreadPoolExecutor(max_workers=4) as executor:  # Adjust the number of workers as needed\n","                futures = []\n","                for hidden_channels, kernel_size, num_layers, lr in hyperparameter_combinations:\n","                    # Submit each combination to the ThreadPoolExecutor\n","                    futures.append(executor.submit(self._train_single_config, hidden_channels, kernel_size, num_layers, lr, epochs, pbar))\n","\n","                # Process each future as it completes\n","                for future in as_completed(futures):\n","                    result = future.result()\n","                    val_loss, hidden_channels, kernel_size, num_layers, lr, model = result\n","\n","                    # Check for the best configuration\n","                    if val_loss < best_val_loss:\n","                        best_val_loss = val_loss\n","                        best_config = (hidden_channels, kernel_size, num_layers, lr)\n","                        best_model = model\n","\n","        # Log the best configuration\n","        print(f\"Best config: hidden_channels={best_config[0]}, kernel_size={best_config[1]}, num_layers={best_config[2]}, lr={best_config[3]}\")\n","        print(f\"Best validation loss: {best_val_loss}\")\n","\n","        return best_model, best_config\n"]},{"cell_type":"markdown","metadata":{"id":"FfVrv7aFIp1G"},"source":["We also define a function to run the model on the trainig values."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1726743704466,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"rpwW_fvbIp1G"},"outputs":[],"source":["def test_model(model, test_features, test_targets, criterion):\n","    model.eval()  # Set the model to evaluation mode\n","\n","    with torch.no_grad():  # Disable gradient calculations for testing\n","        test_output = model(test_features)  # Forward pass on the test data\n","\n","        # Ensure we are selecting the correct dimensions from the model output\n","        # Assuming that the output is of shape (time, 1, depth, lat, lon), so we squeeze to remove the singleton dimension\n","        predicted_chlorophyll_test = test_output.squeeze(1)  # Shape should be (time, depth, lat, lon)\n","\n","        # Calculate the test loss\n","        test_loss = criterion(predicted_chlorophyll_test, test_targets)\n","\n","    print(f\"Test Loss: {test_loss.item()}\")\n","\n","    return predicted_chlorophyll_test\n"]},{"cell_type":"markdown","metadata":{"id":"eAgFobgIIp1G"},"source":["## Small test on CPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_m6evErIp1G","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Define the small test dataset dimensions\n","test_time_steps = 15  # Use only 15 time steps\n","test_lat_range = slice(0, 50)  # Use the first 50 latitude values\n","test_lon_range = slice(0, 50)  # Use the first 50 longitude values\n","\n","# Slice the data to get a smaller subset for the test\n","chlorophyll_test_tensor = chlorophyll_tensor[:test_time_steps, :, test_lat_range, test_lon_range]\n","features_test_tensor = features_tensor[:test_time_steps, :, :, test_lat_range, test_lon_range]\n","\n","# Print shapes to verify\n","print(f\"Chlorophyll test tensor shape: {chlorophyll_test_tensor.shape}\")\n","print(f\"Features test tensor shape: {features_test_tensor.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-YjCykpDIp1H","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Split data into 70% training, 15% validation, 15% test\n","train_size = int(0.7 * features_test_tensor.shape[0])  # Shape[0] corresponds to time_steps\n","val_size = int(0.15 * features_test_tensor.shape[0])    # 15% for validation\n","test_size = features_test_tensor.shape[0] - train_size - val_size  # Remaining for test set\n","\n","# Split features into train, validation, and test sets\n","train_features = features_test_tensor[:train_size, :, :, :, :]   # First 70% of time steps for training\n","val_features = features_test_tensor[train_size:train_size+val_size, :, :, :, :]  # Next 15% for validation\n","test_features = features_test_tensor[train_size+val_size:, :, :, :, :]  # Last 15% for test\n","\n","# Split targets (chlorophyll) accordingly\n","train_targets = chlorophyll_test_tensor[:train_size, :, :, :]    # First 70% of chlorophyll targets for training\n","val_targets = chlorophyll_test_tensor[train_size:train_size+val_size, :, :, :]  # Next 15% for validation\n","test_targets = chlorophyll_test_tensor[train_size+val_size:, :, :, :]  # Last 15% for test\n"]},{"cell_type":"markdown","metadata":{"id":"WTo-5wLEIp1H"},"source":["Testing without the tuner"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"61EpoHFGIp1H","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Set parameters for ConvLSTM\n","batch_size = 1\n","input_channels = features_test_tensor.shape[1]  # Number of features (channels)\n","hidden_channels = 16  # Set a small number of hidden channels for the test\n","kernel_size = 3  # Use a small kernel size\n","num_layers = 2  # Test with a single layer for now\n","\n","# Initialize the ConvLSTM model\n","conv_lstm = ConvLSTM(input_channels=input_channels,\n","                     hidden_channels=hidden_channels,\n","                     kernel_size=kernel_size,\n","                     num_layers=num_layers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vj-oIS3aIp1H","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Define the loss function (Mean Squared Error for regression tasks)\n","criterion = nn.MSELoss()\n","\n","# Define the optimizer\n","optimizer = optim.Adam(conv_lstm.parameters(), lr=0.001)\n","\n","# Set the number of training epochs\n","epochs = 5  # You can adjust the number of epochs\n","\n","# Training loop with validation\n","for epoch in range(epochs):\n","    # TRAINING PHASE\n","    conv_lstm.train()  # Set the model to training mode\n","\n","    optimizer.zero_grad()  # Zero out the gradients\n","\n","    # Forward pass (training)\n","    train_output = conv_lstm(train_features)\n","    predicted_chlorophyll_train = train_output[:, 0, :, :, :]  # Select the first hidden channel\n","\n","    # Calculate training loss\n","    train_loss = criterion(predicted_chlorophyll_train, train_targets)\n","\n","    # Backward pass and optimization\n","    train_loss.backward()\n","    optimizer.step()\n","\n","    # VALIDATION PHASE\n","    conv_lstm.eval()  # Set the model to evaluation mode\n","    with torch.no_grad():  # Disable gradient computation for validation\n","        val_output = conv_lstm(val_features)\n","        predicted_chlorophyll_val = val_output[:, 0, :, :, :]  # Select the first hidden channel\n","\n","        # Calculate validation loss\n","        val_loss = criterion(predicted_chlorophyll_val, val_targets)\n","\n","    # Print training and validation loss for the current epoch\n","    print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss.item()}, Val Loss: {val_loss.item()}\")\n","\n","print(\"Training and validation complete!\")\n"]},{"cell_type":"markdown","metadata":{"id":"0394haPYIp1H"},"source":["Now we can apply our hypertuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HPO6JLhrIp1I","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["# Prepare your hyperparameter ranges\n","hidden_channels_list = [8, 16, 32]\n","kernel_size_list = [3, 5]\n","num_layers_list = [1, 2]\n","lr_list = [0.001, 0.0005]\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# Create an instance of HyperparameterTuner with your prepared data\n","tuner = HyperparameterTuner(\n","    input_channels=train_features.shape[1],  # Ensure this is the correct number of channels\n","    train_data=(train_features, train_targets),  # Training features and targets\n","    val_data=(val_features, val_targets),  # Validation features and targets\n","    criterion=nn.MSELoss(),  # Loss function\n","    device=device  # Device to run on (CPU or GPU)\n",")\n","\n","# Call the tuning method\n","best_model, best_config = tuner.tune(\n","    hidden_channels_list=hidden_channels_list,\n","    kernel_size_list=kernel_size_list,\n","    num_layers_list=num_layers_list,\n","    lr_list=lr_list,\n","    epochs=5  # Number of epochs for each tuning iteration\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JuMV7i3lIp1I","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bb9AiT0DIp1I","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":6,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["predicted_chlorophyll_test = test_model(best_model, test_features, test_targets, criterion)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFOqr-r7Ip1J","executionInfo":{"status":"aborted","timestamp":1726743621378,"user_tz":240,"elapsed":6,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["plt.figure(figsize=(10, 5))\n","plt.plot(test_targets[0, :, :, :].flatten().cpu().numpy(), label='True Values')\n","plt.plot(predicted_chlorophyll_test[0, :, :, :].flatten().cpu().numpy(), label='Predicted Values')\n","plt.legend()\n","plt.title('Predicted vs. Actual Chlorophyll Concentrations (Test Data)')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"rLUDyRxjIp1J"},"source":["## Spit the data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1726743621378,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"rDSux8ZAIp1J"},"outputs":[],"source":["# Define the split percentages\n","train_split = 0.6\n","val_split = 0.2\n","test_split = 1 - train_split - val_split\n","\n","# Number of time steps\n","n_time_steps = features_tensor.shape[0]\n","\n","# Indices for the splits (70% train, 20% validation, 10% test)\n","train_idx = int(n_time_steps * 0.7)  # 70% for training\n","val_idx = int(n_time_steps * (0.7 + 0.2))  # 20% for validation, 10% for testing\n","\n","# Split the features and target tensors along the time dimension\n","train_features = features_tensor[:train_idx, :, :, :, :]\n","train_target = chlorophyll_tensor[:train_idx, :, :, :]\n","\n","val_features = features_tensor[train_idx:val_idx, :, :, :, :]\n","val_target = chlorophyll_tensor[train_idx:val_idx, :, :, :]\n","\n","test_features = features_tensor[val_idx:, :, :, :, :]\n","test_target = chlorophyll_tensor[val_idx:, :, :, :]\n","\n","\n","# Print shapes to verify correctness\n","print(f\"Train features shape: {train_features.shape}\")\n","print(f\"Train target shape: {train_target.shape}\")\n","print(f\"Validation features shape: {val_features.shape}\")\n","print(f\"Validation target shape: {val_target.shape}\")\n","print(f\"Test features shape: {test_features.shape}\")\n","print(f\"Test target shape: {test_target.shape}\")\n"]},{"cell_type":"markdown","metadata":{"id":"5gdPcQ5TIp1J"},"source":["Now move to the GPU."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1726743621378,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"ElxM5PcCIp1N"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move data to GPU (only when necessary)\n","train_features = train_features.to(device)\n","train_target = train_target.to(device)\n","val_features = val_features.to(device)\n","val_target = val_target.to(device)\n","test_features = test_features.to(device)\n","test_target = test_target.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1726743621379,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"ld_4MAigiJin"},"outputs":[],"source":["!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7,"status":"aborted","timestamp":1726743621379,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"},"user_tz":240},"id":"jzGlOoUwIp1N"},"outputs":[],"source":["# Prepare your hyperparameter ranges\n","hidden_channels_list = [8, 16, 32]\n","kernel_size_list = [3, 5]\n","num_layers_list = [1, 2]\n","lr_list = [0.001, 0.0005]\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","# Create an instance of HyperparameterTuner with your prepared data\n","tuner = HyperparameterTuner(\n","    input_channels=train_features.shape[1],  # Ensure this is the correct number of channels\n","    train_data=(train_features, train_target),  # Training features and targets\n","    val_data=(val_features, val_target),  # Validation features and targets\n","    criterion=nn.MSELoss(),  # Loss function\n","    device=device  # Device to run on (CPU or GPU)\n",")\n","\n","# Call the tuning method\n","best_model, best_config = tuner.tune(\n","    hidden_channels_list=hidden_channels_list,\n","    kernel_size_list=kernel_size_list,\n","    num_layers_list=num_layers_list,\n","    lr_list=lr_list,\n","    epochs=5  # Number of epochs for each tuning iteration\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipp1rjskgZ_h","executionInfo":{"status":"aborted","timestamp":1726743621379,"user_tz":240,"elapsed":7,"user":{"displayName":"Claire Merriman","userId":"10396121315400453588"}}},"outputs":[],"source":["predicted_chlorophyll_test = test_model(best_model, test_features, test_targets, criterion)\n","# Assuming predicted_chlorophyll_test is your model's output and test_targets are the true values\n","plt.figure(figsize=(10, 5))\n","plt.plot(test_targets[0, :, :, :].flatten().cpu().numpy(), label='True Values')\n","plt.plot(predicted_chlorophyll_test[0, :, :, :].flatten().cpu().numpy(), label='Predicted Values')\n","plt.legend()\n","plt.title('Predicted vs. Actual Chlorophyll Concentrations (Test Data)')\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}