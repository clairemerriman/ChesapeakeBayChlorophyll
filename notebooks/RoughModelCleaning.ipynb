{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WO-iYAOCLvMd"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive/')\n","\n","# %cd /content/drive/MyDrive/ChesapeakeBay/notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ! pip install  xarray"]},{"cell_type":"markdown","metadata":{"id":"F2jBtOxalCp6"},"source":["# Code"]},{"cell_type":"markdown","metadata":{"id":"BK870kQElCp8"},"source":["## Common imports and functions"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vEsl6LBllCp9"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import json\n","import xarray as xr\n","import requests\n","import io\n","\n","import logging\n","from tqdm import tqdm  # For progress bar\n","# Configure logging instead of print\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","\n","import torch\n"]},{"cell_type":"markdown","metadata":{"id":"Skvo51F5lCp9"},"source":["We will read in the buoy data and water quality data from CSV. In both cases, we need to turn data and time columns into a datatime column numeric data. However, the columns are organized differently, so need to be processed differently."]},{"cell_type":"code","execution_count":31,"metadata":{"id":"ogt2DS8Ao8js"},"outputs":[],"source":["# Function to process buoy data\n","def process_buoy_datetime(df, year_col, month_col, day_col, hour_col, minute_col, second_col):\n","    # Create a copy of the original DataFrame to avoid editing it\n","    df_copy = df.copy()\n","\n","    # Combine the datetime components into a single string\n","    combined_col = df_copy[year_col].astype(str) + '-' + \\\n","                           df_copy[month_col].astype(str).str.zfill(2) + '-' + \\\n","                           df_copy[day_col].astype(str).str.zfill(2) + ' ' + \\\n","                           df_copy[hour_col].astype(str).str.zfill(2) + ':' + \\\n","                           df_copy[minute_col].astype(str).str.zfill(2) + ':' + \\\n","                           df_copy[second_col].astype(str).str.zfill(2)\n","\n","    # Convert to a datetime object\n","    df_copy['timestamp'] = pd.to_datetime(combined_col, format='%Y-%m-%d %H:%M:%S', errors=\"coerce\")\n","\n","    # Drop the original datetime component columns\n","    df_copy.drop(columns=[year_col, month_col, day_col, hour_col, minute_col, second_col], inplace=True)\n","\n","    return df_copy\n","\n","\n","# Function to process water quality data\n","def process_water_datetime(df, date_col, time_col):\n","    # Create a copy of the original DataFrame to avoid editing it\n","    df_copy = df.copy()\n","\n","    # Combine date and time strings\n","    combined_col = df_copy[date_col] + \" \" + df_copy[time_col]\n","\n","    # Convert the combined date and time strings into a datetime object\n","    df_copy['timestamp'] = pd.to_numeric(pd.to_datetime(combined_col, format='%m/%d/%Y %H:%M:%S', errors=\"coerce\"))/ 10**12\n","\n","    # Drop the original date and time columns\n","    df_copy.drop(columns=[date_col, time_col], inplace=True)\n","\n","    return df_copy"]},{"cell_type":"markdown","metadata":{"id":"Ff4MPV15lCp_"},"source":["## Read and clean buoy\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"YVrPiIRtaSR0"},"outputs":[],"source":["# read in Jun's buoy data\n","buoy_df = pd.read_csv('../data/plank_ChesapeakeBay_all_buoys.csv')\n","buoy_timestamped = process_buoy_datetime(buoy_df, 'Sample_year', 'Sample_month', 'Sample_day', 'Sample_hour', 'Sample_minute', 'Sample_second')"]},{"cell_type":"markdown","metadata":{"id":"wR3abzWbo8jt"},"source":["The buoy data also contains columns with `QC` that describe the quality of the reading. Since we do not need that information, let's drop those columns."]},{"cell_type":"code","execution_count":33,"metadata":{"id":"lhxhQNDmo8jt"},"outputs":[],"source":["buoy_timestamped = buoy_timestamped.loc[:, ~buoy_timestamped.columns.str.contains('QC')]"]},{"cell_type":"markdown","metadata":{"id":"5gt81jMXlCqC"},"source":["There were also some issues with the way the data was combined, let's fix that."]},{"cell_type":"code","execution_count":34,"metadata":{"id":"hdzuLo93o8ju"},"outputs":[],"source":["buoy_timestamped = buoy_timestamped.drop(columns=['Latitude_y','Longitude_y'])\n"]},{"cell_type":"markdown","metadata":{"id":"3hhJu0eBlCqD"},"source":["And some more cleaning to remove invalid latitude and longitude measurements."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"ecE3Q1mElCqD","outputId":"bfcd194b-632d-409f-b1ec-c21112fd1b79"},"outputs":[{"data":{"text/plain":["Index(['Latitude', 'Longitude', 'Air Temperature', 'Air pressure', 'Humidity',\n","       'Wind speed', 'Wind Direction', 'Temperature', 'Salinity',\n","       'Chlorophyll', 'Turbidity', 'Oxygen', 'Significant wave height',\n","       'Wave from direction', 'Wave period', 'North surface currents',\n","       'East surface currents', 'timestamp'],\n","      dtype='object')"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Cell generated by Data Wrangler.\n","\"\"\"\n","def clean_data(buoy_data):\n","    # Filter rows based on column: 'Longitude_x'\n","    buoy_data = buoy_data[(buoy_data['Longitude_x'].notna()) & (buoy_data['Longitude_x'] < -70) & (buoy_data['Longitude_x'] > -80)]\n","    # Filter rows based on column: 'Latitude_x'\n","    buoy_data = buoy_data[(buoy_data['Latitude_x'].notna()) & (buoy_data['Latitude_x'] > 35) & (buoy_data['Latitude_x'] < 40)]\n","    # Rename column 'Latitude_x' to 'Latitude'\n","    buoy_data = buoy_data.rename(columns={'Latitude_x': 'Latitude','Longitude_x': 'Longitude'})\n","    return buoy_data\n","\n","buoy_data_clean = clean_data(buoy_timestamped.copy())\n","buoy_data_clean.columns"]},{"cell_type":"markdown","metadata":{"id":"or1aC9_GlCqE"},"source":["The next step is preparing the data to align with our satellite data.  Since the buoys move a bit, the latitude and longitude values should be rounded before aggregation. The satellite data uses two decimal places, and that should also be reasonable for the buoy data.Since the buoy data is taken every 6-60 minutes, depending on the parameter, and the satellite data is roughly daily, we will use the daily mean measurements."]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Air Temperature</th>\n","      <th>Air pressure</th>\n","      <th>Humidity</th>\n","      <th>Wind speed</th>\n","      <th>Wind Direction</th>\n","      <th>Temperature</th>\n","      <th>Salinity</th>\n","      <th>Chlorophyll</th>\n","      <th>Turbidity</th>\n","      <th>Oxygen</th>\n","      <th>Significant wave height</th>\n","      <th>Wave from direction</th>\n","      <th>Wave period</th>\n","      <th>North surface currents</th>\n","      <th>East surface currents</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>39.2</td>\n","      <td>-76.57</td>\n","      <td>14.4</td>\n","      <td>1028.18</td>\n","      <td>66.8</td>\n","      <td>1.0</td>\n","      <td>155.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2009-11-18 19:10:00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>39.2</td>\n","      <td>-76.57</td>\n","      <td>14.4</td>\n","      <td>1028.22</td>\n","      <td>67.1</td>\n","      <td>0.9</td>\n","      <td>164.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2009-11-18 19:20:00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>39.2</td>\n","      <td>-76.57</td>\n","      <td>14.4</td>\n","      <td>1028.30</td>\n","      <td>67.2</td>\n","      <td>1.0</td>\n","      <td>182.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2009-11-18 19:30:00</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>39.2</td>\n","      <td>-76.57</td>\n","      <td>14.4</td>\n","      <td>1028.01</td>\n","      <td>67.7</td>\n","      <td>1.0</td>\n","      <td>174.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2009-11-18 19:50:00</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>39.2</td>\n","      <td>-76.57</td>\n","      <td>14.5</td>\n","      <td>1027.94</td>\n","      <td>68.2</td>\n","      <td>0.9</td>\n","      <td>183.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.0</td>\n","      <td>137.8</td>\n","      <td>5.1</td>\n","      <td>656.13</td>\n","      <td>6242.61</td>\n","      <td>2009-11-18 20:00:00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Latitude  Longitude  Air Temperature  Air pressure  Humidity  Wind speed  \\\n","1      39.2     -76.57             14.4       1028.18      66.8         1.0   \n","2      39.2     -76.57             14.4       1028.22      67.1         0.9   \n","3      39.2     -76.57             14.4       1028.30      67.2         1.0   \n","5      39.2     -76.57             14.4       1028.01      67.7         1.0   \n","6      39.2     -76.57             14.5       1027.94      68.2         0.9   \n","\n","   Wind Direction  Temperature  Salinity  Chlorophyll  Turbidity  Oxygen  \\\n","1           155.0          NaN       NaN          NaN        NaN     NaN   \n","2           164.0          NaN       NaN          NaN        NaN     NaN   \n","3           182.0          NaN       NaN          NaN        NaN     NaN   \n","5           174.0          NaN       NaN          NaN        NaN     NaN   \n","6           183.0          NaN       NaN          NaN        NaN     NaN   \n","\n","   Significant wave height  Wave from direction  Wave period  \\\n","1                      NaN                  NaN          NaN   \n","2                      NaN                  NaN          NaN   \n","3                      NaN                  NaN          NaN   \n","5                      NaN                  NaN          NaN   \n","6                      0.0                137.8          5.1   \n","\n","   North surface currents  East surface currents           timestamp  \n","1                     NaN                    NaN 2009-11-18 19:10:00  \n","2                     NaN                    NaN 2009-11-18 19:20:00  \n","3                     NaN                    NaN 2009-11-18 19:30:00  \n","5                     NaN                    NaN 2009-11-18 19:50:00  \n","6                  656.13                6242.61 2009-11-18 20:00:00  "]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Cell generated by Data Wrangler.\n","\"\"\"\n","def clean_data(buoy_data_clean):\n","    # Round column 'Latitude' (Number of decimals: 2)\n","    buoy_data_clean = buoy_data_clean.round({'Latitude': 2})\n","    # Round column 'Longitude' (Number of decimals: 2)\n","    buoy_data_clean = buoy_data_clean.round({'Longitude': 2})\n","    return buoy_data_clean\n","\n","buoy_data_rounded = clean_data(buoy_data_clean.copy())\n","buoy_data_rounded.head()"]},{"cell_type":"code","execution_count":55,"metadata":{"id":"NAe1oiHhlCqE","outputId":"a4988042-d49a-4d1c-de90-153adad35119"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date</th>\n","      <th>Latitude</th>\n","      <th>Longitude</th>\n","      <th>Air Temperature</th>\n","      <th>Air pressure</th>\n","      <th>Humidity</th>\n","      <th>Wind speed</th>\n","      <th>Wind Direction</th>\n","      <th>Temperature</th>\n","      <th>Salinity</th>\n","      <th>Chlorophyll</th>\n","      <th>Turbidity</th>\n","      <th>Oxygen</th>\n","      <th>Significant wave height</th>\n","      <th>Wave from direction</th>\n","      <th>Wave period</th>\n","      <th>North surface currents</th>\n","      <th>East surface currents</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2007-04-25</td>\n","      <td>36.02</td>\n","      <td>-76.13</td>\n","      <td>29.215000</td>\n","      <td>1011.667750</td>\n","      <td>42.947500</td>\n","      <td>4.062500</td>\n","      <td>226.100000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2007-04-26</td>\n","      <td>36.01</td>\n","      <td>-76.14</td>\n","      <td>11.966667</td>\n","      <td>1018.933333</td>\n","      <td>86.466667</td>\n","      <td>0.366667</td>\n","      <td>331.166667</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2007-04-26</td>\n","      <td>36.02</td>\n","      <td>-76.13</td>\n","      <td>16.616279</td>\n","      <td>1016.557674</td>\n","      <td>77.915504</td>\n","      <td>1.196124</td>\n","      <td>230.984496</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2007-04-27</td>\n","      <td>36.02</td>\n","      <td>-76.13</td>\n","      <td>20.625874</td>\n","      <td>1012.079790</td>\n","      <td>81.541958</td>\n","      <td>2.308392</td>\n","      <td>205.846154</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2007-04-28</td>\n","      <td>36.02</td>\n","      <td>-76.13</td>\n","      <td>19.752083</td>\n","      <td>1010.187431</td>\n","      <td>77.270833</td>\n","      <td>1.111806</td>\n","      <td>166.201389</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         Date  Latitude  Longitude  Air Temperature  Air pressure   Humidity  \\\n","0  2007-04-25     36.02     -76.13        29.215000   1011.667750  42.947500   \n","1  2007-04-26     36.01     -76.14        11.966667   1018.933333  86.466667   \n","2  2007-04-26     36.02     -76.13        16.616279   1016.557674  77.915504   \n","3  2007-04-27     36.02     -76.13        20.625874   1012.079790  81.541958   \n","4  2007-04-28     36.02     -76.13        19.752083   1010.187431  77.270833   \n","\n","   Wind speed  Wind Direction  Temperature  Salinity  Chlorophyll  Turbidity  \\\n","0    4.062500      226.100000          NaN       NaN          NaN        NaN   \n","1    0.366667      331.166667          NaN       NaN          NaN        NaN   \n","2    1.196124      230.984496          NaN       NaN          NaN        NaN   \n","3    2.308392      205.846154          NaN       NaN          NaN        NaN   \n","4    1.111806      166.201389          NaN       NaN          NaN        NaN   \n","\n","   Oxygen  Significant wave height  Wave from direction  Wave period  \\\n","0     NaN                      NaN                  NaN          NaN   \n","1     NaN                      NaN                  NaN          NaN   \n","2     NaN                      NaN                  NaN          NaN   \n","3     NaN                      NaN                  NaN          NaN   \n","4     NaN                      NaN                  NaN          NaN   \n","\n","   North surface currents  East surface currents  \n","0                     NaN                    NaN  \n","1                     NaN                    NaN  \n","2                     NaN                    NaN  \n","3                     NaN                    NaN  \n","4                     NaN                    NaN  "]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Assuming buoy_data is your DataFrame\n","# buoy_data_rounded['timestamp'] = pd.to_datetime(buoy_data_rounded['timestamp'])  # Convert to datetime if not already\n","buoy_data_rounded.set_index('timestamp', inplace=True)  # Set the timestamp as the index\n","\n","# Group by date and latitude/longitude, aggregating measurement columns\n","daily_aggregate = (\n","    buoy_data_rounded.groupby([buoy_data_rounded.index.date, 'Latitude', 'Longitude'])\n","    .agg('mean')  # Default behavior is to calculate the mean, ignoring NaNs\n","    .reset_index()\n",")\n","\n","# Rename the date column for clarity\n","daily_aggregate.rename(columns={'level_0': 'Date'}, inplace=True)\n","\n","# Check the resulting DataFrame\n","daily_aggregate.head()\n"]},{"cell_type":"markdown","metadata":{"id":"Yq8BZ4ItlCqE"},"source":["Finally, we will only retain parameters with data in at least 50% of the rows."]},{"cell_type":"code","execution_count":56,"metadata":{"id":"1BA72OL9poBN","outputId":"fab97796-87bd-443e-a8e7-08e613c77c9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Remaining columns: Index(['Date', 'Latitude', 'Longitude', 'Air Temperature', 'Air pressure',\n","       'Humidity', 'Wind speed', 'Wind Direction'],\n","      dtype='object')\n"]}],"source":["threshold = 0.21\n","\n","missing_percentage = daily_aggregate.isnull().mean()\n","\n","columns_to_keep = missing_percentage[missing_percentage <= threshold].index\n","\n","# Create a new DataFrame with only the columns to keep\n","daily_aggregate = daily_aggregate[columns_to_keep]\n","\n","print('Remaining columns:', daily_aggregate.columns)"]},{"cell_type":"code","execution_count":57,"metadata":{"id":"3rE3pVfXvlfj","outputId":"6764632a-c9e4-49c6-bd4d-eee249a6ee28"},"outputs":[{"data":{"text/plain":["Date                object\n","Latitude           float64\n","Longitude          float64\n","Air Temperature    float64\n","Air pressure       float64\n","Humidity           float64\n","Wind speed         float64\n","Wind Direction     float64\n","dtype: object"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["daily_aggregate.dtypes"]},{"cell_type":"markdown","metadata":{"id":"Ac9d9pDqlCqH"},"source":["Now we can save this aggregated data in a CSV to access later."]},{"cell_type":"code","execution_count":58,"metadata":{"id":"IrBv0LyklCqH"},"outputs":[],"source":["daily_aggregate.to_csv('../data/buoy_aggregate.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"c95C4dwTlCqH"},"source":["## Read and clean water"]},{"cell_type":"markdown","metadata":{"id":"uIoEmcpTlCqH"},"source":["For the water quality data, we will read in the CSV, drop columns that are not needed for the model. Let's drop the columns related to how the data was collected: `TotalDepth` refers to the station, `FieldActivityId`,`ProjectIdentifier`, and `Source`, `Problems`, and `Details` are about the sample collection.  `CBSeg2003` identifies the region of the Bay. `UpperPycnocline`, `LowerPycnocline`, and `Layer` are related to the layer of the water column."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MGQIjW-BbV4r"},"outputs":[],"source":["water_quality_df = pd.read_csv('../data/plank_ChesapeakeBayWater_pivoted.csv')\n","\n","water_quality_df = water_quality_df.drop(columns=['CBSeg2003', 'FieldActivityId',\n","       'Cruise', 'ProjectIdentifier', 'Source', 'Station', 'Layer', 'SampleType', 'Problem', 'Details','StationDepth','UpperPycnocline', 'LowerPycnocline'])\n","\n","water_quality_timestamped = process_water_datetime(water_quality_df, 'SampleDate', 'SampleTime')\n"]},{"cell_type":"markdown","metadata":{"id":"2WW4T8VzlCqI"},"source":["Several of the text columns have a dictionary to convert to the existing numerical values. We will read in this dictionary to transform those columns into floats.\n","\n","This dictionary comes from the [Water Quality Database Database Design and Data Dictionary](https://d18lev1ok5leia.cloudfront.net/chesapeakebay/documents/cbwqdb2004_rb.pdf)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oegxjbSLo8ju"},"outputs":[],"source":["# Load JSON file\n","with open('../data/waterQualityOtherColumns.json', 'r') as file:\n","    json_data = json.load(file)\n","\n","# Function to convert integers to floats in a nested dictionary\n","def convert_numbers_to_floats(d):\n","    for key, value in d.items():\n","        if isinstance(value, dict):\n","            convert_numbers_to_floats(value)\n","        elif isinstance(value, int):\n","            d[key] = float(value)\n","\n","# Convert numbers to floats in the loaded JSON data\n","convert_numbers_to_floats(json_data)\n","\n","# Iterate through each column in the DataFrame\n","for column in water_quality_timestamped.columns:\n","    # Check if the column's dtype is not float\n","    if water_quality_timestamped[column].dtype != 'float':\n","        # Check if the column name exists in the JSON\n","        if column in json_data:\n","            # Fetch the corresponding inner dictionary from JSON\n","            inner_dict = json_data[column]\n","\n","            # If the inner_dict values are floats, map them accordingly\n","            if all(isinstance(value, float) for value in inner_dict.values()):\n","                # Replace the column values based on the JSON data\n","                water_quality_timestamped[column] = water_quality_timestamped[column].map(lambda x: inner_dict.get(x, x))"]},{"cell_type":"markdown","metadata":{"id":"6fc_WURalCqI"},"source":["Again, we will keep variables only if data is available in at least 50% of the rows."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"OY0EpVWSlCqI","outputId":"41c0d72f-83a2-4d0a-b039-d194bffca6bb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Remaining columns: Index(['CHLA', 'DO', 'PH', 'PHEO', 'SALINITY', 'SECCHI', 'SIGMA_T', 'SPCOND',\n","       'TSS', 'WTEMP', 'SampleDepth', 'Latitude', 'Longitude', 'timestamp'],\n","      dtype='object')\n"]}],"source":["threshold = 0.5\n","\n","missing_percentage = water_quality_timestamped.isnull().mean()\n","\n","columns_to_keep = missing_percentage[missing_percentage <= threshold].index\n","\n","# Create a new DataFrame with only the columns to keep\n","water_quality_timestamped = water_quality_timestamped[columns_to_keep]\n","\n","print('Remaining columns:', water_quality_timestamped.columns)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"l6WCBnb7Ocgj","outputId":"7d46d448-8d69-4b99-9cf9-e4e7c904ff3c"},"outputs":[{"data":{"text/plain":["CHLA           float64\n","DO             float64\n","PH             float64\n","PHEO           float64\n","SALINITY       float64\n","SECCHI         float64\n","SIGMA_T        float64\n","SPCOND         float64\n","TSS            float64\n","WTEMP          float64\n","SampleDepth    float64\n","Latitude       float64\n","Longitude      float64\n","timestamp      float64\n","dtype: object"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["water_quality_timestamped.dtypes"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["water_quality_timestamped.to_csv('../data/water_cleaned.csv')"]},{"cell_type":"markdown","metadata":{"id":"iXWb88QplCqJ"},"source":["## Read satellite"]},{"cell_type":"markdown","metadata":{"id":"SspinUm2lCqJ"},"source":["We will read in the MODIS Chlorophyll_a data from 2020."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4BtgvHqacWD6","outputId":"8f17b96d-1cd0-4f25-f5da-626e1ec1b1e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing datasets: 100%|██████████| 340/340 [01:15<00:00,  4.53it/s]\n"]}],"source":["def process_nc4_from_stream(url):\n","    try:\n","        # Send a GET request to the URL\n","        response = requests.get(url)\n","        response.raise_for_status()  # Check for request errors\n","\n","        # Create an in-memory file-like object from the response content\n","        file_like = io.BytesIO(response.content)\n","\n","        # Open the NetCDF4 file from the in-memory file-like object using xarray with netCDF4 engine\n","        with xr.open_dataset(file_like, decode_cf=False) as ds:\n","            # Print dataset information\n","            return ds\n","\n","    except Exception as e:\n","        print(f'Error processing NetCDF4 file from URL: {e}')\n","        return None\n","\n","def read_urls_from_file(file_path, base_url):\n","    \"\"\"Reads URLs from a file and returns a list of full URLs.\"\"\"\n","    urls = []\n","    try:\n","        with open(file_path, 'r') as file:\n","            for line in file:\n","                # Remove 'https:' and leading/trailing whitespace, then construct the full URL\n","                line = line.strip().replace('https:', '')\n","                full_url = f\"{base_url}{line}\"\n","                urls.append(full_url)\n","    except Exception as e:\n","        logging.error(f'Error reading URLs from file: {e}')\n","    return urls\n","\n","def process_all_datasets(urls):\n","    \"\"\"Process datasets from all provided URLs.\"\"\"\n","    datasets = []\n","\n","    for url in tqdm(urls, desc=\"Processing datasets\"):\n","        ds = process_nc4_from_stream(url)\n","        if ds:\n","            datasets.append(ds)  # Only append if dataset was successfully processed\n","\n","    return datasets\n","\n","# Example usage\n","base_url = 'https://www.star.nesdis.noaa.gov/pub/socd1/ecn/data/modis/chl-swir/daily/cd/'  # Replace with actual base URL\n","file_path = '../data/MODISSchlor_filelist.txt'  # Path to the file containing the URLs\n","\n","# Read URLs from file\n","urls = read_urls_from_file(file_path, base_url)\n","\n","# Process datasets from URLs\n","satellite_xarray_list = process_all_datasets(urls)"]},{"cell_type":"markdown","metadata":{"id":"Tz0RdOk1lCqJ"},"source":["Here is an example of what the data looks like. Note that the format of the data changes at index 55."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qw_NDBzalCqK","outputId":"df3ed44e-435d-48e9-bfa8-88da763a0baa"},"outputs":[{"data":{"text/html":["<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n","<defs>\n","<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n","<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n","<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n","<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n","</symbol>\n","<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n","<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n","<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n","<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n","<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n","</symbol>\n","</defs>\n","</svg>\n","<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n"," *\n"," */\n","\n",":root {\n","  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n","  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n","  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n","  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n","  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n","  --xr-background-color: var(--jp-layout-color0, white);\n","  --xr-background-color-row-even: var(--jp-layout-color1, white);\n","  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n","}\n","\n","html[theme=dark],\n","body[data-theme=dark],\n","body.vscode-dark {\n","  --xr-font-color0: rgba(255, 255, 255, 1);\n","  --xr-font-color2: rgba(255, 255, 255, 0.54);\n","  --xr-font-color3: rgba(255, 255, 255, 0.38);\n","  --xr-border-color: #1F1F1F;\n","  --xr-disabled-color: #515151;\n","  --xr-background-color: #111111;\n","  --xr-background-color-row-even: #111111;\n","  --xr-background-color-row-odd: #313131;\n","}\n","\n",".xr-wrap {\n","  display: block !important;\n","  min-width: 300px;\n","  max-width: 700px;\n","}\n","\n",".xr-text-repr-fallback {\n","  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n","  display: none;\n","}\n","\n",".xr-header {\n","  padding-top: 6px;\n","  padding-bottom: 6px;\n","  margin-bottom: 4px;\n","  border-bottom: solid 1px var(--xr-border-color);\n","}\n","\n",".xr-header > div,\n",".xr-header > ul {\n","  display: inline;\n","  margin-top: 0;\n","  margin-bottom: 0;\n","}\n","\n",".xr-obj-type,\n",".xr-array-name {\n","  margin-left: 2px;\n","  margin-right: 10px;\n","}\n","\n",".xr-obj-type {\n","  color: var(--xr-font-color2);\n","}\n","\n",".xr-sections {\n","  padding-left: 0 !important;\n","  display: grid;\n","  grid-template-columns: 150px auto auto 1fr 20px 20px;\n","}\n","\n",".xr-section-item {\n","  display: contents;\n","}\n","\n",".xr-section-item input {\n","  display: none;\n","}\n","\n",".xr-section-item input + label {\n","  color: var(--xr-disabled-color);\n","}\n","\n",".xr-section-item input:enabled + label {\n","  cursor: pointer;\n","  color: var(--xr-font-color2);\n","}\n","\n",".xr-section-item input:enabled + label:hover {\n","  color: var(--xr-font-color0);\n","}\n","\n",".xr-section-summary {\n","  grid-column: 1;\n","  color: var(--xr-font-color2);\n","  font-weight: 500;\n","}\n","\n",".xr-section-summary > span {\n","  display: inline-block;\n","  padding-left: 0.5em;\n","}\n","\n",".xr-section-summary-in:disabled + label {\n","  color: var(--xr-font-color2);\n","}\n","\n",".xr-section-summary-in + label:before {\n","  display: inline-block;\n","  content: '►';\n","  font-size: 11px;\n","  width: 15px;\n","  text-align: center;\n","}\n","\n",".xr-section-summary-in:disabled + label:before {\n","  color: var(--xr-disabled-color);\n","}\n","\n",".xr-section-summary-in:checked + label:before {\n","  content: '▼';\n","}\n","\n",".xr-section-summary-in:checked + label > span {\n","  display: none;\n","}\n","\n",".xr-section-summary,\n",".xr-section-inline-details {\n","  padding-top: 4px;\n","  padding-bottom: 4px;\n","}\n","\n",".xr-section-inline-details {\n","  grid-column: 2 / -1;\n","}\n","\n",".xr-section-details {\n","  display: none;\n","  grid-column: 1 / -1;\n","  margin-bottom: 5px;\n","}\n","\n",".xr-section-summary-in:checked ~ .xr-section-details {\n","  display: contents;\n","}\n","\n",".xr-array-wrap {\n","  grid-column: 1 / -1;\n","  display: grid;\n","  grid-template-columns: 20px auto;\n","}\n","\n",".xr-array-wrap > label {\n","  grid-column: 1;\n","  vertical-align: top;\n","}\n","\n",".xr-preview {\n","  color: var(--xr-font-color3);\n","}\n","\n",".xr-array-preview,\n",".xr-array-data {\n","  padding: 0 5px !important;\n","  grid-column: 2;\n","}\n","\n",".xr-array-data,\n",".xr-array-in:checked ~ .xr-array-preview {\n","  display: none;\n","}\n","\n",".xr-array-in:checked ~ .xr-array-data,\n",".xr-array-preview {\n","  display: inline-block;\n","}\n","\n",".xr-dim-list {\n","  display: inline-block !important;\n","  list-style: none;\n","  padding: 0 !important;\n","  margin: 0;\n","}\n","\n",".xr-dim-list li {\n","  display: inline-block;\n","  padding: 0;\n","  margin: 0;\n","}\n","\n",".xr-dim-list:before {\n","  content: '(';\n","}\n","\n",".xr-dim-list:after {\n","  content: ')';\n","}\n","\n",".xr-dim-list li:not(:last-child):after {\n","  content: ',';\n","  padding-right: 5px;\n","}\n","\n",".xr-has-index {\n","  font-weight: bold;\n","}\n","\n",".xr-var-list,\n",".xr-var-item {\n","  display: contents;\n","}\n","\n",".xr-var-item > div,\n",".xr-var-item label,\n",".xr-var-item > .xr-var-name span {\n","  background-color: var(--xr-background-color-row-even);\n","  margin-bottom: 0;\n","}\n","\n",".xr-var-item > .xr-var-name:hover span {\n","  padding-right: 5px;\n","}\n","\n",".xr-var-list > li:nth-child(odd) > div,\n",".xr-var-list > li:nth-child(odd) > label,\n",".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n","  background-color: var(--xr-background-color-row-odd);\n","}\n","\n",".xr-var-name {\n","  grid-column: 1;\n","}\n","\n",".xr-var-dims {\n","  grid-column: 2;\n","}\n","\n",".xr-var-dtype {\n","  grid-column: 3;\n","  text-align: right;\n","  color: var(--xr-font-color2);\n","}\n","\n",".xr-var-preview {\n","  grid-column: 4;\n","}\n","\n",".xr-index-preview {\n","  grid-column: 2 / 5;\n","  color: var(--xr-font-color2);\n","}\n","\n",".xr-var-name,\n",".xr-var-dims,\n",".xr-var-dtype,\n",".xr-preview,\n",".xr-attrs dt {\n","  white-space: nowrap;\n","  overflow: hidden;\n","  text-overflow: ellipsis;\n","  padding-right: 10px;\n","}\n","\n",".xr-var-name:hover,\n",".xr-var-dims:hover,\n",".xr-var-dtype:hover,\n",".xr-attrs dt:hover {\n","  overflow: visible;\n","  width: auto;\n","  z-index: 1;\n","}\n","\n",".xr-var-attrs,\n",".xr-var-data,\n",".xr-index-data {\n","  display: none;\n","  background-color: var(--xr-background-color) !important;\n","  padding-bottom: 5px !important;\n","}\n","\n",".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",".xr-var-data-in:checked ~ .xr-var-data,\n",".xr-index-data-in:checked ~ .xr-index-data {\n","  display: block;\n","}\n","\n",".xr-var-data > table {\n","  float: right;\n","}\n","\n",".xr-var-name span,\n",".xr-var-data,\n",".xr-index-name div,\n",".xr-index-data,\n",".xr-attrs {\n","  padding-left: 25px !important;\n","}\n","\n",".xr-attrs,\n",".xr-var-attrs,\n",".xr-var-data,\n",".xr-index-data {\n","  grid-column: 1 / -1;\n","}\n","\n","dl.xr-attrs {\n","  padding: 0;\n","  margin: 0;\n","  display: grid;\n","  grid-template-columns: 125px auto;\n","}\n","\n",".xr-attrs dt,\n",".xr-attrs dd {\n","  padding: 0;\n","  margin: 0;\n","  float: left;\n","  padding-right: 10px;\n","  width: auto;\n","}\n","\n",".xr-attrs dt {\n","  font-weight: normal;\n","  grid-column: 1;\n","}\n","\n",".xr-attrs dt:hover span {\n","  display: inline-block;\n","  background: var(--xr-background-color);\n","  padding-right: 10px;\n","}\n","\n",".xr-attrs dd {\n","  grid-column: 2;\n","  white-space: pre-wrap;\n","  word-break: break-all;\n","}\n","\n",".xr-icon-database,\n",".xr-icon-file-text2,\n",".xr-no-icon {\n","  display: inline-block;\n","  vertical-align: middle;\n","  width: 1em;\n","  height: 1.5em !important;\n","  stroke-width: 0;\n","  stroke: currentColor;\n","  fill: currentColor;\n","}\n","</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt; Size: 2MB\n","Dimensions:      (x: 243, y: 358, time: 1, n_vals: 2, level: 1)\n","Coordinates:\n","  * x            (x) float64 2kB -8.628e+06 -8.627e+06 ... -8.293e+06 -8.292e+06\n","  * y            (y) float64 3kB 4.839e+06 4.838e+06 ... 4.344e+06 4.343e+06\n","  * time         (time) float64 8B 1.583e+09\n","  * level        (level) float64 8B 0.0\n","Dimensions without coordinates: n_vals\n","Data variables:\n","    coord_ref    int32 4B ...\n","    lat          (y, x) float64 696kB ...\n","    lon          (y, x) float64 696kB ...\n","    time_bounds  (time, n_vals) float64 16B ...\n","    chlor_a      (time, level, y, x) float32 348kB ...\n","Attributes: (12/23)\n","    cw:polygon_longitude:           [-77.51046055 -76.75502232 -75.99958408 -...\n","    source:                         AQUA_MODIS\n","    institution:                    USDOC/NOAA/NESDIS CoastWatch\n","    history:                        [2020-03-05 07:07:36 EST cwutils-3.5.1.76...\n","    dcs:createInstitution:          USDOC/NOAA/NESDIS CoastWatch\n","    dcs:createDateTime:             2020-03-05T12:07:36Z\n","    ...                             ...\n","    dcs:observedPropertyAlgorithm:  Unknown\n","    dcs:processingLevel:            Level 3\n","    cw:orbit_type:                  ascending\n","    cw:pass_type:                   day\n","    cw:polygon_latitude:            [40.00562071 40.00562071 40.00562071 40.0...\n","    Conventions:                    CF-1.4</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-b028c5ca-edca-4bda-bf46-76a5341a1c1b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-b028c5ca-edca-4bda-bf46-76a5341a1c1b' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>x</span>: 243</li><li><span class='xr-has-index'>y</span>: 358</li><li><span class='xr-has-index'>time</span>: 1</li><li><span>n_vals</span>: 2</li><li><span class='xr-has-index'>level</span>: 1</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-ba4785e8-3669-48c1-b28d-d00a5ea53956' class='xr-section-summary-in' type='checkbox'  checked><label for='section-ba4785e8-3669-48c1-b28d-d00a5ea53956' class='xr-section-summary' >Coordinates: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>-8.628e+06 ... -8.292e+06</div><input id='attrs-c000f97c-c177-409a-96c8-bf6b01478aa0' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c000f97c-c177-409a-96c8-bf6b01478aa0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-253558dc-0fe7-4327-879e-4ff577881ee3' class='xr-var-data-in' type='checkbox'><label for='data-253558dc-0fe7-4327-879e-4ff577881ee3' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>projection_x_coordinate</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([-8628425., -8627035., -8625645., ..., -8294825., -8293435., -8292045.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>4.839e+06 4.838e+06 ... 4.343e+06</div><input id='attrs-73238ae4-c733-482a-b818-5f243cb608ac' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-73238ae4-c733-482a-b818-5f243cb608ac' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-479f78d7-3f6d-4fe0-83ba-10b3d19826c6' class='xr-var-data-in' type='checkbox'><label for='data-479f78d7-3f6d-4fe0-83ba-10b3d19826c6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>projection_y_coordinate</dd><dt><span>units :</span></dt><dd>m</dd></dl></div><div class='xr-var-data'><pre>array([4839285., 4837895., 4836505., ..., 4345835., 4344445., 4343055.])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>1.583e+09</div><input id='attrs-f77fafec-8dd0-4963-8b72-b527b0d7e519' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-f77fafec-8dd0-4963-8b72-b527b0d7e519' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b0e972bb-20b6-45b7-afaf-e2c825cd37ed' class='xr-var-data-in' type='checkbox'><label for='data-b0e972bb-20b6-45b7-afaf-e2c825cd37ed' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>time</dd><dt><span>units :</span></dt><dd>seconds since 1970-01-01 00:00:00 UTC</dd><dt><span>bounds :</span></dt><dd>time_bounds</dd></dl></div><div class='xr-var-data'><pre>array([1.583259e+09])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>level</span></div><div class='xr-var-dims'>(level)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0</div><input id='attrs-c2129ff3-803e-486d-b1a7-52e94a75da63' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-c2129ff3-803e-486d-b1a7-52e94a75da63' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-1a06e05f-51f0-4637-91d7-2d4cb1014e4a' class='xr-var-data-in' type='checkbox'><label for='data-1a06e05f-51f0-4637-91d7-2d4cb1014e4a' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>height</dd><dt><span>units :</span></dt><dd>m</dd><dt><span>positive :</span></dt><dd>up</dd></dl></div><div class='xr-var-data'><pre>array([0.])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-360d26c4-2eab-4532-90c7-f8dc885e342f' class='xr-section-summary-in' type='checkbox'  checked><label for='section-360d26c4-2eab-4532-90c7-f8dc885e342f' class='xr-section-summary' >Data variables: <span>(5)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>coord_ref</span></div><div class='xr-var-dims'>()</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-443eca29-52b5-442b-8722-045b462d4f5b' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-443eca29-52b5-442b-8722-045b462d4f5b' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-b7a9bf64-1107-4a04-b948-321141d834a5' class='xr-var-data-in' type='checkbox'><label for='data-b7a9bf64-1107-4a04-b948-321141d834a5' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>longitude_of_prime_meridian :</span></dt><dd>0.0</dd><dt><span>longitude_of_projection_origin :</span></dt><dd>0.0</dd><dt><span>standard_parallel :</span></dt><dd>0.0</dd><dt><span>false_easting :</span></dt><dd>0.0</dd><dt><span>false_northing :</span></dt><dd>0.0</dd><dt><span>semi_major_axis :</span></dt><dd>6378137.0</dd><dt><span>inverse_flattening :</span></dt><dd>298.257223653</dd><dt><span>grid_mapping_name :</span></dt><dd>mercator</dd></dl></div><div class='xr-var-data'><pre>[1 values with dtype=int32]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lat</span></div><div class='xr-var-dims'>(y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-34965533-6a96-485e-a12d-30ff3cbf76e2' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-34965533-6a96-485e-a12d-30ff3cbf76e2' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-469b25dc-ba48-46f8-ac6e-fefa08433879' class='xr-var-data-in' type='checkbox'><label for='data-469b25dc-ba48-46f8-ac6e-fefa08433879' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>latitude</dd><dt><span>units :</span></dt><dd>degrees_north</dd></dl></div><div class='xr-var-data'><pre>[86994 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>lon</span></div><div class='xr-var-dims'>(y, x)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-6c1a1e24-82b7-46e0-bce8-37c951ac3d08' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-6c1a1e24-82b7-46e0-bce8-37c951ac3d08' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-93885191-71fd-4827-bf2a-61e92b963021' class='xr-var-data-in' type='checkbox'><label for='data-93885191-71fd-4827-bf2a-61e92b963021' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>longitude</dd><dt><span>units :</span></dt><dd>degrees_east</dd></dl></div><div class='xr-var-data'><pre>[86994 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>time_bounds</span></div><div class='xr-var-dims'>(time, n_vals)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-4d1b16c1-1f22-4097-afcc-45adac6c4cd0' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-4d1b16c1-1f22-4097-afcc-45adac6c4cd0' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a42ce818-1823-41a1-a623-f99dde7731fa' class='xr-var-data-in' type='checkbox'><label for='data-a42ce818-1823-41a1-a623-f99dde7731fa' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>[2 values with dtype=float64]</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>chlor_a</span></div><div class='xr-var-dims'>(time, level, y, x)</div><div class='xr-var-dtype'>float32</div><div class='xr-var-preview xr-preview'>...</div><input id='attrs-4958f0c9-916c-457f-a739-24a25e04abfd' class='xr-var-attrs-in' type='checkbox' ><label for='attrs-4958f0c9-916c-457f-a739-24a25e04abfd' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-77af9516-2991-445a-9aa8-9a1d1b8b6bc6' class='xr-var-data-in' type='checkbox'><label for='data-77af9516-2991-445a-9aa8-9a1d1b8b6bc6' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'><dt><span>standard_name :</span></dt><dd>mass_concentration_of_chlorophyll_in_sea_water</dd><dt><span>long_name :</span></dt><dd>Chlorophyll Concentration, OC3 Algorithm</dd><dt><span>units :</span></dt><dd>mg m^-3</dd><dt><span>coordinates :</span></dt><dd>lat lon</dd><dt><span>cell_methods :</span></dt><dd>area: mean</dd><dt><span>grid_mapping :</span></dt><dd>coord_ref</dd><dt><span>source :</span></dt><dd>oc3_algorithm menghua_wang_nirswir_correction</dd><dt><span>missing_value :</span></dt><dd>-1.0</dd></dl></div><div class='xr-var-data'><pre>[86994 values with dtype=float32]</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-1562a269-1065-495e-ad0c-5df7ab1d0b11' class='xr-section-summary-in' type='checkbox'  ><label for='section-1562a269-1065-495e-ad0c-5df7ab1d0b11' class='xr-section-summary' >Indexes: <span>(4)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-c6cc044e-479d-4e40-aece-38a04a1a3191' class='xr-index-data-in' type='checkbox'/><label for='index-c6cc044e-479d-4e40-aece-38a04a1a3191' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([-8628425.0, -8627035.0, -8625645.0, -8624255.0, -8622865.0, -8621475.0,\n","       -8620085.0, -8618695.0, -8617305.0, -8615915.0,\n","       ...\n","       -8304555.0, -8303165.0, -8301775.0, -8300385.0, -8298995.0, -8297605.0,\n","       -8296215.0, -8294825.0, -8293435.0, -8292045.0],\n","      dtype=&#x27;float64&#x27;, name=&#x27;x&#x27;, length=243))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-7cdd2072-a10e-4e68-9a75-aca000d59ac2' class='xr-index-data-in' type='checkbox'/><label for='index-7cdd2072-a10e-4e68-9a75-aca000d59ac2' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([4839285.0, 4837895.0, 4836505.0, 4835115.0, 4833725.0, 4832335.0,\n","       4830945.0, 4829555.0, 4828165.0, 4826775.0,\n","       ...\n","       4355565.0, 4354175.0, 4352785.0, 4351395.0, 4350005.0, 4348615.0,\n","       4347225.0, 4345835.0, 4344445.0, 4343055.0],\n","      dtype=&#x27;float64&#x27;, name=&#x27;y&#x27;, length=358))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-f4665d9b-7325-4f41-bf72-7672a5ffc779' class='xr-index-data-in' type='checkbox'/><label for='index-f4665d9b-7325-4f41-bf72-7672a5ffc779' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([1583258860.0], dtype=&#x27;float64&#x27;, name=&#x27;time&#x27;))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>level</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-70bfc2a6-376e-4354-9db0-47fa1b062240' class='xr-index-data-in' type='checkbox'/><label for='index-70bfc2a6-376e-4354-9db0-47fa1b062240' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([0.0], dtype=&#x27;float64&#x27;, name=&#x27;level&#x27;))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-64338cc2-ce25-4217-b6aa-b46435618e3d' class='xr-section-summary-in' type='checkbox'  ><label for='section-64338cc2-ce25-4217-b6aa-b46435618e3d' class='xr-section-summary' >Attributes: <span>(23)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>cw:polygon_longitude :</span></dt><dd>[-77.51046055 -76.75502232 -75.99958408 -75.24414584 -74.4887076\n"," -74.4887076  -74.4887076  -74.4887076  -74.4887076  -75.24414584\n"," -75.99958408 -76.75502232 -77.51046055 -77.51046055 -77.51046055\n"," -77.51046055 -77.51046055]</dd><dt><span>source :</span></dt><dd>AQUA_MODIS</dd><dt><span>institution :</span></dt><dd>USDOC/NOAA/NESDIS CoastWatch</dd><dt><span>history :</span></dt><dd>[2020-03-05 07:07:36 EST cwutils-3.5.1.762 20191112_223457 ronald.vogel] cwexport --dcs --cw /disks/data034/data/modis/chl-swir/daily/cd/MODWCW_2020063_DAILY_AQUA_CHLORA_CD_1KM.hdf /data/aftp/socd1/ecn/data/modis/chl-swir/daily/cd/MODWCW_2020063_DAILY_AQUA_CHLORA_CD_1KM.nc4</dd><dt><span>dcs:createInstitution :</span></dt><dd>USDOC/NOAA/NESDIS CoastWatch</dd><dt><span>dcs:createDateTime :</span></dt><dd>2020-03-05T12:07:36Z</dd><dt><span>dcs:acquisitionStartDateTime :</span></dt><dd>2020-03-03T17:15:11Z</dd><dt><span>dcs:acquisitionEndDateTime :</span></dt><dd>2020-03-03T19:00:09Z</dd><dt><span>dcs:sensor :</span></dt><dd>MODIS</dd><dt><span>dcs:sensorPlatform :</span></dt><dd>Aqua</dd><dt><span>dcs:mapProjection :</span></dt><dd>Mercator</dd><dt><span>dcs:geodeticDatum :</span></dt><dd>WGS 84</dd><dt><span>dcs:northernLatitude :</span></dt><dd>40.005620706616064</dd><dt><span>dcs:southernLatitude :</span></dt><dd>36.491529335419145</dd><dt><span>dcs:easternLongitude :</span></dt><dd>-74.48870760106858</dd><dt><span>dcs:westernLongitude :</span></dt><dd>-77.51046055378983</dd><dt><span>dcs:observedProperty :</span></dt><dd>Unknown</dd><dt><span>dcs:observedPropertyAlgorithm :</span></dt><dd>Unknown</dd><dt><span>dcs:processingLevel :</span></dt><dd>Level 3</dd><dt><span>cw:orbit_type :</span></dt><dd>ascending</dd><dt><span>cw:pass_type :</span></dt><dd>day</dd><dt><span>cw:polygon_latitude :</span></dt><dd>[40.00562071 40.00562071 40.00562071 40.00562071 40.00562071 39.14320224\n"," 38.26999972 37.38608208 36.49152934 36.49152934 36.49152934 36.49152934\n"," 36.49152934 37.38608208 38.26999972 39.14320224 40.00562071]</dd><dt><span>Conventions :</span></dt><dd>CF-1.4</dd></dl></div></li></ul></div></div>"],"text/plain":["<xarray.Dataset> Size: 2MB\n","Dimensions:      (x: 243, y: 358, time: 1, n_vals: 2, level: 1)\n","Coordinates:\n","  * x            (x) float64 2kB -8.628e+06 -8.627e+06 ... -8.293e+06 -8.292e+06\n","  * y            (y) float64 3kB 4.839e+06 4.838e+06 ... 4.344e+06 4.343e+06\n","  * time         (time) float64 8B 1.583e+09\n","  * level        (level) float64 8B 0.0\n","Dimensions without coordinates: n_vals\n","Data variables:\n","    coord_ref    int32 4B ...\n","    lat          (y, x) float64 696kB ...\n","    lon          (y, x) float64 696kB ...\n","    time_bounds  (time, n_vals) float64 16B ...\n","    chlor_a      (time, level, y, x) float32 348kB ...\n","Attributes: (12/23)\n","    cw:polygon_longitude:           [-77.51046055 -76.75502232 -75.99958408 -...\n","    source:                         AQUA_MODIS\n","    institution:                    USDOC/NOAA/NESDIS CoastWatch\n","    history:                        [2020-03-05 07:07:36 EST cwutils-3.5.1.76...\n","    dcs:createInstitution:          USDOC/NOAA/NESDIS CoastWatch\n","    dcs:createDateTime:             2020-03-05T12:07:36Z\n","    ...                             ...\n","    dcs:observedPropertyAlgorithm:  Unknown\n","    dcs:processingLevel:            Level 3\n","    cw:orbit_type:                  ascending\n","    cw:pass_type:                   day\n","    cw:polygon_latitude:            [40.00562071 40.00562071 40.00562071 40.0...\n","    Conventions:                    CF-1.4"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["ds = satellite_xarray_list[60]\n","ds"]},{"cell_type":"markdown","metadata":{"id":"GlScgIXZlCqK"},"source":["Here are the variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXvFutmelCqK","outputId":"1b0796e3-fe17-4362-cfe7-e291c39db334"},"outputs":[{"data":{"text/plain":["Data variables:\n","    coord_ref    int32 4B ...\n","    lat          (y, x) float64 696kB ...\n","    lon          (y, x) float64 696kB ...\n","    time_bounds  (time, n_vals) float64 16B ...\n","    chlor_a      (time, level, y, x) float32 348kB ..."]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["ds.data_vars"]},{"cell_type":"markdown","metadata":{"id":"Cm88XBFAlCqK"},"source":["Since the different datasets have different configurations, we need to write a function to find all of the configurations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IO3BVRaGlCqK","outputId":"eecbe484-08e5-421e-eda5-6bc7fa388242"},"outputs":[{"data":{"text/plain":["[{'coordinate variables': {'time': {'dimensions': ('time',)},\n","   'level': {'dimensions': ('level',)}},\n","  'data variables': {'coord_ref': {'dimensions': ()},\n","   'x': {'dimensions': ('column',)},\n","   'y': {'dimensions': ('row',)},\n","   'lat': {'dimensions': ('row', 'column')},\n","   'lon': {'dimensions': ('row', 'column')},\n","   'time_bounds': {'dimensions': ('time', 'n_vals')},\n","   'chlor_a': {'dimensions': ('time', 'level', 'row', 'column')}}},\n"," {'coordinate variables': {'x': {'dimensions': ('x',)},\n","   'y': {'dimensions': ('y',)}},\n","  'data variables': {'lat': {'dimensions': ('y', 'x')},\n","   'lon': {'dimensions': ('y', 'x')},\n","   'chlor_a': {'dimensions': ('time', 'level', 'y', 'x')}}}]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def extract_variables_from_datasets(xarray_list):\n","    \"\"\"\n","    Extracts detailed information about variables, including their dimensions and data types,\n","    from each dataset in a list of xarray datasets.\n","\n","    Parameters:\n","    xarray_list (list): A list of xarray.Dataset objects.\n","\n","    Returns:\n","    list: Each entry is a dictionary representing a dataset with detailed variable information.\n","    \"\"\"\n","    unique_variables = set()  # To track uniqueness\n","    dataset_details = []      # To hold the final details\n","\n","    for ds in xarray_list:\n","        variable_details = {}\n","        coordinate_details = {}\n","        for var_name, data_array in ds.data_vars.items():\n","            # Create a tuple to represent the uniqueness of the variable\n","            unique_key = (var_name, data_array.dims, str(data_array.dtype), data_array.shape)\n","            if unique_key not in unique_variables:\n","                unique_variables.add(unique_key)\n","                variable_details[var_name] = {\n","                    'dimensions': data_array.dims,\n","                    # 'data_type': data_array.dtype,\n","                    # 'shape': data_array.shape\n","                }\n","        for var_name, data_array in ds.coords.items():\n","            # Create a tuple to represent the uniqueness of the variable\n","            unique_key = (var_name, data_array.dims, str(data_array.dtype), data_array.shape)\n","            if unique_key not in unique_variables:\n","                unique_variables.add(unique_key)\n","                coordinate_details[var_name] = {\n","                    'dimensions': data_array.dims,\n","                    # 'data_type': data_array.dtype,\n","                    # 'shape': data_array.shape\n","                }\n","\n","        if variable_details:  # Only add to the list if there are new, unique details\n","            dataset_details.append({\n","                'coordinate variables' : coordinate_details,\n","                'data variables': variable_details\n","            })\n","\n","    return dataset_details\n","\n","\n","extract_variables_from_datasets(satellite_xarray_list)"]},{"cell_type":"markdown","metadata":{"id":"amDRIWDylCqL"},"source":["Now that we know the formats, we can read adjust the xarrays to have a common format. We will use the format that has the indeces (`row`,`column`) instead of the projected coordinates `x` and `y`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wRcbJcqGlCqR"},"outputs":[],"source":["def reformat_lat_lon_chl(xr_dataset):\n","    \"\"\"\n","    Reformat lat, lon, and chlor_a variables in an xarray dataset to ensure they use (row, column) structure.\n","    Converts (y, x) to (row, column), where row corresponds to y indices and column to x indices.\n","    \"\"\"\n","\n","    # Check if lat/lon are already in (row, column) format\n","    if 'row' in xr_dataset['lat'].dims and 'column' in xr_dataset['lat'].dims:\n","        return xr_dataset\n","\n","    # Ensure lat/lon are in (y, x) format\n","    if 'y' in xr_dataset['lat'].dims and 'x' in xr_dataset['lat'].dims:\n","        # Get the dimensions of y and x\n","        num_rows = xr_dataset.sizes['y']\n","        num_cols = xr_dataset.sizes['x']\n","\n","        # Create `row` and `column` variables as literal indices\n","        row = np.arange(num_rows)  # row indices: [0, 1, 2, ..., num_rows - 1]\n","        column = np.arange(num_cols)  # column indices: [0, 1, 2, ..., num_cols - 1]\n","\n","        # Assign `row` and `column` as coordinates\n","        xr_dataset = xr_dataset.assign_coords(row=('y', row), column=('x', column))\n","\n","        # Explicitly handle lat and lon as data variables, not coordinates\n","        lat_values = xr_dataset['lat'].values\n","        lon_values = xr_dataset['lon'].values\n","\n","        # Remove lat and lon from the coordinates (to avoid merge conflicts)\n","        xr_dataset = xr_dataset.reset_coords(['lat', 'lon'], drop=True)\n","\n","        # Reassign lat and lon as data variables using (row, column) structure\n","        lat_new = np.empty((num_rows, num_cols))\n","        lon_new = np.empty((num_rows, num_cols))\n","        for y in range(num_rows):\n","            for x in range(num_cols):\n","                lat_new[y, x] = lat_values[y, x]\n","                lon_new[y, x] = lon_values[y, x]\n","\n","        xr_dataset['lat'] = xr.DataArray(lat_new, dims=('row', 'column'))\n","        xr_dataset['lon'] = xr.DataArray(lon_new, dims=('row', 'column'))\n","\n","        # Update all variables that depend on (y, x) to (row, column)\n","        for var in xr_dataset.data_vars:\n","            if 'y' in xr_dataset[var].dims and 'x' in xr_dataset[var].dims:\n","                data_values = xr_dataset[var].values\n","                new_data = np.empty((xr_dataset[var].shape[0], xr_dataset[var].shape[1], num_rows, num_cols))\n","                for y in range(num_rows):\n","                    for x in range(num_cols):\n","                        new_data[:, :, y, x] = data_values[:, :, y, x]\n","                xr_dataset[var] = xr.DataArray(new_data, dims=('time', 'level', 'row', 'column'))\n","\n","        # Remove old y and x dimensions\n","        xr_dataset = xr_dataset.drop_dims(['y', 'x'])\n","        # reorder\n","        xr_dataset.transpose('column','row','time','n_vals','level')\n","\n","    return xr_dataset"]},{"cell_type":"markdown","metadata":{"id":"RNBSgZ3alCqV"},"source":["Now we apply this function to our list of datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VR_1PQllCqV"},"outputs":[],"source":["satellite_xarray_list_reformated = []\n","\n","for ds in satellite_xarray_list:\n","    satellite_xarray_list_reformated.append(reformat_lat_lon_chl(ds))"]},{"cell_type":"markdown","metadata":{"id":"J9r4k4pnlCqV"},"source":["### Add the buoy data to the satelitte data"]},{"cell_type":"markdown","metadata":{"id":"P_v_IPxClCqV"},"source":["We will read in the buoy data, then create a dictionary that aggreates the data by day. This dictionary will save time when aligning with the satellite data, as the grouping csv rows takes time."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5t8cdTBlCqW","outputId":"60ec33d1-de0e-4fe7-f915-c4f27db1e821"},"outputs":[{"data":{"text/plain":["Index(['Date', 'Latitude', 'Longitude', 'Air Temperature', 'Air pressure',\n","       'Humidity', 'Wind speed', 'Wind Direction'],\n","      dtype='object')"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["# Load buoy data from CSV\n","buoy_data_agg = pd.read_csv('../data/buoy_aggregate.csv')\n","\n","buoy_data_agg['Date'] = pd.to_datetime(buoy_data_agg['Date'])\n","buoy_data_agg.columns"]},{"cell_type":"markdown","metadata":{"id":"J06HRYeYlCqW"},"source":["Now we need to group the rows by date so that we can merge with the corresponding satellite data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"op0PPxoplCqW"},"outputs":[],"source":["def preprocess_dataframe_by_date(df):\n","    # Ensure 'Date' is in datetime format\n","    df['Date'] = pd.to_datetime(df['Date']).dt.date\n","    # Group DataFrame by date\n","    grouped_data = {date: group for date, group in df.groupby('Date')}\n","    return grouped_data\n","\n","buoy_dates_dict = preprocess_dataframe_by_date(buoy_data_agg)"]},{"cell_type":"markdown","metadata":{"id":"G-XfoBvSlCqX"},"source":["We need to clean the satelitte data by dropping unused variables. We also need to add the variables from the buoy data. First, we will find the buoy data for the correct date. Then, for each location in the the xarray, we find the closest buoy and attach the daily mean measurement for each of the variables."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oofvz4BxlCqX"},"outputs":[],"source":["def merge_and_clean_xarray(ds, grouped_data, variables_to_drop=['x','y','coord_ref','time_bounds']):\n","    try:\n","        #Define the variable with the date for the xarray\n","        time_value = ds['time'].values[0]\n","        date_value = pd.to_datetime(time_value, unit='s').date()\n","\n","        if date_value not in grouped_data:\n","            raise ValueError(f\"No matching rows found for date: {date_value}\")\n","\n","        df_filtered = grouped_data[date_value]\n","\n","        #Define where to find latidue and longitued\n","        latitudes = ds['lat'].values\n","        longitudes = ds['lon'].values\n","        csv_lat = df_filtered['Latitude'].values\n","        csv_lon = df_filtered['Longitude'].values\n","\n","        #find the closest buoy to each point in the satellite data\n","        lat_diffs = latitudes[:, :, np.newaxis] - csv_lat\n","        lon_diffs = longitudes[:, :, np.newaxis] - csv_lon\n","        distances = np.sqrt(lat_diffs**2 + lon_diffs**2)\n","        closest_indices = np.argmin(distances, axis=2)\n","\n","        closest_data = {}\n","        for col in df_filtered.columns:\n","            if col not in ['Latitude', 'Longitude', 'Date']:\n","                closest_data[col] = df_filtered[col].values[closest_indices]\n","\n","        new_ds = ds.copy(deep=True)\n","        for col, values in closest_data.items():\n","            new_ds[col] = (('row', 'column'), values)\n","\n","        if variables_to_drop:\n","            new_ds = new_ds.drop_vars(variables_to_drop, errors='ignore')\n","\n","        return new_ds\n","\n","    except Exception as e:\n","        raise RuntimeError(f\"Error merging and cleaning xarray: {str(e)}\")"]},{"cell_type":"markdown","metadata":{"id":"C5ikHgkPlCqX"},"source":["Finally, we define a function to turn the xarrays into pytorchh tensors, and a function that reads through the entire list of xarrays, applies `merge_and_clean_xarray` and then converst to a tensor."]},{"cell_type":"markdown","metadata":{"id":"b-NCSEM0lCqX"},"source":["There must be a better way to do this!!!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dekDM6LElCqX"},"outputs":[],"source":["def convert_xarray_to_tensor(ds):\n","    \"\"\"\n","    Converts an xarray dataset to a PyTorch tensor.\n","\n","    Parameters:\n","    ds (xarray.Dataset): The cleaned and merged xarray dataset.\n","\n","    Returns:\n","    torch.Tensor: The PyTorch tensor created from the xarray dataset.\n","    \"\"\"\n","    time_value = ds['time'].values[0]  # Extract the first time value (it's a 1D array)\n","\n","    # Extract latitude and longitude values\n","    lat_values = torch.tensor(ds['lat'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","    lon_values = torch.tensor(ds['lon'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","\n","    # define the number of rows\n","    rows = lat_values.shape[0]  # Number of latitude points\n","    columns = lat_values.shape[1]  # Number of longitude points\n","\n","    variable_count = len(ds.data_vars)-2\n","    satelite_tensor = torch.empty((1, rows, columns, 2, variable_count), dtype=torch.float32)\n","\n","    satelite_tensor[0,:,:,:,:] = time_value\n","    # Assign latitude and longitude directly\n","    satelite_tensor[0, :, :, 0, :] = lat_values.unsqueeze(-1)  # Adding a new dimension for latitudes\n","    satelite_tensor[0, :, :, 1, :] = lon_values.unsqueeze(-1)  # Adding a new dimension for longitudes\n","\n","    # read in variables\n","    chlor_a_values = torch.tensor(ds['chlor_a'].values[0, 0, :, :], dtype=torch.float32) # Shape: (rows, columns)\n","    air_temp_values = torch.tensor(ds['Air Temperature'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","    air_pressure_values = torch.tensor(ds['Air pressure'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","    humidity_values = torch.tensor(ds['Humidity'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","    wind_speed_values = torch.tensor(ds['Wind speed'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","    wind_direction_values = torch.tensor(ds['Wind Direction'].values, dtype=torch.float32)  # Shape: (rows, columns)\n","\n","    satelite_tensor[0,:,:,:,0] =chlor_a_values.unsqueeze(-1)\n","    satelite_tensor[0,:,:,:,1] =air_temp_values.unsqueeze(-1)\n","    satelite_tensor[0,:,:,:,2] =air_pressure_values.unsqueeze(-1)\n","    satelite_tensor[0,:,:,:,3] =humidity_values.unsqueeze(-1)\n","    satelite_tensor[0,:,:,:,4] =wind_speed_values.unsqueeze(-1)\n","    satelite_tensor[0,:,:,:,5] =wind_direction_values.unsqueeze(-1)\n","\n","    return satelite_tensor\n","\n","def process_xarrays_to_tensor(xarray_list, grouped_data, variables_to_drop=None):\n","    tensors = []\n","    for ds in tqdm(xarray_list, desc=\"Processing xarrays\"):\n","        try:\n","            merged_ds = merge_and_clean_xarray(ds, grouped_data, variables_to_drop)\n","            tensor = convert_xarray_to_tensor(merged_ds)\n","            tensors.append(tensor)\n","        except Exception as e:\n","            logging.error(f\"Failed processing for one xarray: {e}\")\n","\n","    logging.info(\"All xarrays processed.\")\n","    return tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Td3N0GCLlCqY"},"outputs":[],"source":["test_ds = convert_xarray_to_tensor(merge_and_clean_xarray(satellite_xarray_list_reformated[0],buoy_dates_dict))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6X3xR8OlCqY","outputId":"35058646-ab3c-4aaa-c4c6-9ae9f3f87a3b"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing xarrays: 100%|██████████| 340/340 [04:49<00:00,  1.17it/s]\n","2024-09-10 20:36:21,520 - INFO - All xarrays processed.\n"]}],"source":["satelitte_tensor_list = process_xarrays_to_tensor(satellite_xarray_list_reformated,buoy_dates_dict,variables_to_drop)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hdPMNevklCqY","outputId":"1f413570-9e23-4cb9-efd9-e935636fc7ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["All tensors have the same shape: {torch.Size([1, 358, 243, 2, 6])}\n"]}],"source":["unique_shapes = set(tensor.shape for tensor in satelitte_tensor_list)\n","\n","if len(unique_shapes) == 1:\n","    print(\"All tensors have the same shape:\", unique_shapes)\n","else:\n","    print(\"Different shapes found:\", unique_shapes)"]},{"cell_type":"markdown","metadata":{"id":"gOZ-U-NjlCqZ"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"d8HD4l17lCqZ"},"source":["This is an initial model only using the buoy and water quality data. It is really a proof of concept for myself and runs fine on CPU."]},{"cell_type":"markdown","metadata":{"id":"OoJUoWKLlCqZ"},"source":["## Initial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_1nlolIlCqZ"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class IndependentModel(nn.Module):\n","    def __init__(self, buoy_input_size, water_quality_input_size, hidden_size, output_size):\n","        super(IndependentModel, self).__init__()\n","\n","        # Buoy data branch\n","        self.buoy_branch = nn.Sequential(\n","            nn.Linear(buoy_input_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, output_size)  # Output for buoy data\n","        )\n","\n","        # Water quality data branch\n","        self.water_quality_branch = nn.Sequential(\n","            nn.Linear(water_quality_input_size, hidden_size),\n","            nn.ReLU(),\n","            nn.Linear(hidden_size, output_size)  # Output for water quality data\n","        )\n","\n","    def forward(self, buoy_data, water_quality_data):\n","        # Process buoy data\n","        buoy_output = self.buoy_branch(buoy_data)\n","\n","        # Process water quality data\n","        water_quality_output = self.water_quality_branch(water_quality_data)\n","\n","        return buoy_output, water_quality_output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLQmf6pKsoex"},"outputs":[],"source":["# Load and preprocess your data\n","# Example code to load your buoy and water quality data\n","buoy_data = buoy_data_clean\n","\n","water_quality_data = water_quality_timestamped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5pgLddXvlCqa","outputId":"2e9bbe06-e10b-4dd7-e26c-91b4d9a12c8a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/rl/kqt6tbv90l9_pwc4927vdb340000gn/T/ipykernel_92752/1670716204.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  buoy_data_filled = buoy_data.fillna(method='ffill')  # Forward fill\n","/var/folders/rl/kqt6tbv90l9_pwc4927vdb340000gn/T/ipykernel_92752/1670716204.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  water_quality_filled = water_quality_data.fillna(method='ffill')  # Forward fill\n"]}],"source":["# Use forward fill or fill with the mean of each column as a strategy\n","buoy_data_filled = buoy_data.fillna(method='ffill')  # Forward fill\n","# Alternatively, you can use mean imputation\n","# buoy_data_filled = buoy_data.fillna(buoy_data.mean())\n","\n","# Handle NaNs in water quality data\n","water_quality_filled = water_quality_data.fillna(method='ffill')  # Forward fill\n","# Or use mean imputation\n","# water_quality_filled = water_quality_data.fillna(water_quality_data.mean())\n","\n","# Convert to numeric and check for remaining NaNs\n","buoy_data_filled = buoy_data_filled.apply(pd.to_numeric, errors='coerce')\n","water_quality_filled = water_quality_filled.apply(pd.to_numeric, errors='coerce')\n","\n","# Drop rows with NaNs only in critical columns (for example, CHLA)\n","water_quality_filled.dropna(subset=['CHLA'], inplace=True)\n","\n","# Align buoy and water quality data based on the remaining valid indices\n","valid_indices = water_quality_filled.index.intersection(buoy_data_filled.index)\n","buoy_data_final = buoy_data_filled.loc[valid_indices]\n","water_quality_data_final = water_quality_filled.loc[valid_indices]\n","\n","# Convert DataFrames to PyTorch tensors\n","buoy_data_tensor = torch.tensor(buoy_data_final.values.astype(np.float32), dtype=torch.float32)\n","water_quality_data_tensor = torch.tensor(water_quality_data_final.values.astype(np.float32), dtype=torch.float32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-nnqBZHlCqa"},"outputs":[],"source":["# Define the target variable (ensure CHLA is still valid)\n","target = water_quality_data_final['CHLA']\n","target_tensor = torch.tensor(target.values, dtype=torch.float32).view(-1, 1)  # Reshape for output\n","\n","buoy_data_tensor = (buoy_data_tensor - buoy_data_tensor.mean(dim=0)) / buoy_data_tensor.std(dim=0)\n","water_quality_data_tensor = (water_quality_data_tensor - water_quality_data_tensor.mean(dim=0)) / water_quality_data_tensor.std(dim=0)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_Qo4WuOPGfO","outputId":"389ee509-5f67-4954-a5ec-c7c9506b76b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Water Quality Loss: 149.9393\n","Epoch [2/100], Water Quality Loss: 149.9393\n","Epoch [3/100], Water Quality Loss: 149.9393\n","Epoch [4/100], Water Quality Loss: 149.9393\n","Epoch [5/100], Water Quality Loss: 149.9393\n","Epoch [6/100], Water Quality Loss: 149.9393\n","Epoch [7/100], Water Quality Loss: 149.9393\n","Epoch [8/100], Water Quality Loss: 149.9393\n","Epoch [9/100], Water Quality Loss: 149.9393\n","Epoch [10/100], Water Quality Loss: 149.9393\n","Epoch [11/100], Water Quality Loss: 149.9393\n","Epoch [12/100], Water Quality Loss: 149.9393\n","Epoch [13/100], Water Quality Loss: 149.9393\n","Epoch [14/100], Water Quality Loss: 149.9393\n","Epoch [15/100], Water Quality Loss: 149.9393\n","Epoch [16/100], Water Quality Loss: 149.9393\n","Epoch [17/100], Water Quality Loss: 149.9393\n","Epoch [18/100], Water Quality Loss: 149.9393\n","Epoch [19/100], Water Quality Loss: 149.9393\n","Epoch [20/100], Water Quality Loss: 149.9393\n","Epoch [21/100], Water Quality Loss: 149.9393\n","Epoch [22/100], Water Quality Loss: 149.9393\n","Epoch [23/100], Water Quality Loss: 149.9393\n","Epoch [24/100], Water Quality Loss: 149.9393\n","Epoch [25/100], Water Quality Loss: 149.9393\n","Epoch [26/100], Water Quality Loss: 149.9393\n","Epoch [27/100], Water Quality Loss: 149.9393\n","Epoch [28/100], Water Quality Loss: 149.9393\n","Epoch [29/100], Water Quality Loss: 149.9393\n","Epoch [30/100], Water Quality Loss: 149.9393\n","Epoch [31/100], Water Quality Loss: 149.9393\n","Epoch [32/100], Water Quality Loss: 149.9393\n","Epoch [33/100], Water Quality Loss: 149.9393\n","Epoch [34/100], Water Quality Loss: 149.9393\n","Epoch [35/100], Water Quality Loss: 149.9393\n","Epoch [36/100], Water Quality Loss: 149.9393\n","Epoch [37/100], Water Quality Loss: 149.9393\n","Epoch [38/100], Water Quality Loss: 149.9393\n","Epoch [39/100], Water Quality Loss: 149.9393\n","Epoch [40/100], Water Quality Loss: 149.9393\n","Epoch [41/100], Water Quality Loss: 149.9393\n","Epoch [42/100], Water Quality Loss: 149.9393\n","Epoch [43/100], Water Quality Loss: 149.9393\n","Epoch [44/100], Water Quality Loss: 149.9393\n","Epoch [45/100], Water Quality Loss: 149.9393\n","Epoch [46/100], Water Quality Loss: 149.9393\n","Epoch [47/100], Water Quality Loss: 149.9393\n","Epoch [48/100], Water Quality Loss: 149.9393\n","Epoch [49/100], Water Quality Loss: 149.9393\n","Epoch [50/100], Water Quality Loss: 149.9393\n","Epoch [51/100], Water Quality Loss: 149.9393\n","Epoch [52/100], Water Quality Loss: 149.9393\n","Epoch [53/100], Water Quality Loss: 149.9393\n","Epoch [54/100], Water Quality Loss: 149.9393\n","Epoch [55/100], Water Quality Loss: 149.9393\n","Epoch [56/100], Water Quality Loss: 149.9393\n","Epoch [57/100], Water Quality Loss: 149.9393\n","Epoch [58/100], Water Quality Loss: 149.9393\n","Epoch [59/100], Water Quality Loss: 149.9393\n","Epoch [60/100], Water Quality Loss: 149.9393\n","Epoch [61/100], Water Quality Loss: 149.9393\n","Epoch [62/100], Water Quality Loss: 149.9393\n","Epoch [63/100], Water Quality Loss: 149.9393\n","Epoch [64/100], Water Quality Loss: 149.9393\n","Epoch [65/100], Water Quality Loss: 149.9393\n","Epoch [66/100], Water Quality Loss: 149.9393\n","Epoch [67/100], Water Quality Loss: 149.9393\n","Epoch [68/100], Water Quality Loss: 149.9393\n","Epoch [69/100], Water Quality Loss: 149.9393\n","Epoch [70/100], Water Quality Loss: 149.9393\n","Epoch [71/100], Water Quality Loss: 149.9393\n","Epoch [72/100], Water Quality Loss: 149.9393\n","Epoch [73/100], Water Quality Loss: 149.9393\n","Epoch [74/100], Water Quality Loss: 149.9393\n","Epoch [75/100], Water Quality Loss: 149.9393\n","Epoch [76/100], Water Quality Loss: 149.9393\n","Epoch [77/100], Water Quality Loss: 149.9393\n","Epoch [78/100], Water Quality Loss: 149.9393\n","Epoch [79/100], Water Quality Loss: 149.9393\n","Epoch [80/100], Water Quality Loss: 149.9393\n","Epoch [81/100], Water Quality Loss: 149.9393\n","Epoch [82/100], Water Quality Loss: 149.9393\n","Epoch [83/100], Water Quality Loss: 149.9393\n","Epoch [84/100], Water Quality Loss: 149.9393\n","Epoch [85/100], Water Quality Loss: 149.9393\n","Epoch [86/100], Water Quality Loss: 149.9393\n","Epoch [87/100], Water Quality Loss: 149.9393\n","Epoch [88/100], Water Quality Loss: 149.9393\n","Epoch [89/100], Water Quality Loss: 149.9393\n","Epoch [90/100], Water Quality Loss: 149.9393\n","Epoch [91/100], Water Quality Loss: 149.9393\n","Epoch [92/100], Water Quality Loss: 149.9393\n","Epoch [93/100], Water Quality Loss: 149.9393\n","Epoch [94/100], Water Quality Loss: 149.9393\n","Epoch [95/100], Water Quality Loss: 149.9393\n","Epoch [96/100], Water Quality Loss: 149.9393\n","Epoch [97/100], Water Quality Loss: 149.9393\n","Epoch [98/100], Water Quality Loss: 149.9393\n","Epoch [99/100], Water Quality Loss: 149.9393\n","Epoch [100/100], Water Quality Loss: 149.9393\n"]}],"source":["# Create an instance of the model with the correct input sizes\n","model = IndependentModel(\n","    buoy_input_size=buoy_data_tensor.shape[1],  # Should be 18\n","    water_quality_input_size=water_quality_data_tensor.shape[1],  # Should be 14\n","    hidden_size=128,  # Adjust as necessary\n","    output_size=1     # Assuming predicting a single target variable\n",")\n","for epoch in range(num_epochs):\n","    model.train()  # Set the model to training mode\n","    optimizer.zero_grad()  # Clear previous gradients\n","\n","    # Forward pass\n","    buoy_output, water_quality_output = model(buoy_data_tensor, water_quality_data_tensor)\n","\n","    # Check for NaN or Inf in outputs\n","    if torch.isnan(buoy_output).any() or torch.isnan(water_quality_output).any():\n","        print(\"NaN detected in model outputs!\")\n","        break\n","\n","    # Calculate loss\n","    water_quality_loss = criterion(water_quality_output, target_tensor)\n","\n","    # Check for NaN or extremely large values in loss\n","    if torch.isnan(water_quality_loss).item() or water_quality_loss.item() > 1e10:\n","        print(\"Invalid loss detected!\")\n","        break\n","\n","    # Backward pass\n","    water_quality_loss.backward()  # Compute gradients\n","\n","    # Gradient clipping\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","\n","    optimizer.step()  # Update weights\n","\n","    # Print the loss\n","    print(f'Epoch [{epoch + 1}/{num_epochs}], Water Quality Loss: {water_quality_loss.item():.4f}')"]},{"cell_type":"markdown","metadata":{"id":"C8F8QBZNlCqb"},"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
